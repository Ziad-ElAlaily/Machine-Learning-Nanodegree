{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Make and Model Recognizer\n",
    "I shall explore here my tries to reach a good optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense, BatchNormalization, Activation, PReLU, LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from glob import glob\n",
    "from keras import regularizers\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import models\n",
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing\n",
    "\n",
    "### Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5796 images belonging to 196 classes.\n",
      "Found 2348 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   zoom_range=0.25,\n",
    "                                   rotation_range = 50,\n",
    "                                   horizontal_flip=True,\n",
    "                                  validation_split = 0.3)\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255,\n",
    " #                                horizontal_flip = True)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory('My_Cars/trainCropped',\n",
    "                                              target_size=(256, 256),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                              subset='training')\n",
    "test_data = train_datagen.flow_from_directory('My_Cars/trainCropped',\n",
    "                                              target_size=(256, 256),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode='categorical',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CostaPC2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "model.add(conv_base)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(196, activation='softmax'))\n",
    "for layer in conv_base.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 8, 8, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 196)               100548    \n",
      "=================================================================\n",
      "Total params: 14,815,236\n",
      "Trainable params: 100,548\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\CostaPC2\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "182/182 [==============================] - 143s 787ms/step - loss: 5.3168 - acc: 0.0082 - val_loss: 5.1939 - val_acc: 0.0221\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 5.19386, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 2/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 5.1525 - acc: 0.0283 - val_loss: 5.0764 - val_acc: 0.0388\n",
      "\n",
      "Epoch 00002: val_loss improved from 5.19386 to 5.07642, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 3/1000\n",
      "182/182 [==============================] - 136s 745ms/step - loss: 5.0216 - acc: 0.0467 - val_loss: 4.9819 - val_acc: 0.0345\n",
      "\n",
      "Epoch 00003: val_loss improved from 5.07642 to 4.98193, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 4/1000\n",
      "182/182 [==============================] - 137s 750ms/step - loss: 4.9176 - acc: 0.0606 - val_loss: 4.8888 - val_acc: 0.0771\n",
      "\n",
      "Epoch 00004: val_loss improved from 4.98193 to 4.88883, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 5/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 4.8010 - acc: 0.0929 - val_loss: 4.8087 - val_acc: 0.0818\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.88883 to 4.80866, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 6/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 4.7135 - acc: 0.0977 - val_loss: 4.7446 - val_acc: 0.0890\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.80866 to 4.74463, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 7/1000\n",
      "182/182 [==============================] - 136s 746ms/step - loss: 4.6180 - acc: 0.1140 - val_loss: 4.6779 - val_acc: 0.0945\n",
      "\n",
      "Epoch 00007: val_loss improved from 4.74463 to 4.67786, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 8/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 4.5315 - acc: 0.1286 - val_loss: 4.6205 - val_acc: 0.1078\n",
      "\n",
      "Epoch 00008: val_loss improved from 4.67786 to 4.62047, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 9/1000\n",
      "182/182 [==============================] - 136s 746ms/step - loss: 4.4569 - acc: 0.1451 - val_loss: 4.5596 - val_acc: 0.1218\n",
      "\n",
      "Epoch 00009: val_loss improved from 4.62047 to 4.55965, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 10/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 4.3913 - acc: 0.1600 - val_loss: 4.4824 - val_acc: 0.1376\n",
      "\n",
      "Epoch 00010: val_loss improved from 4.55965 to 4.48237, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 11/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 4.3233 - acc: 0.1753 - val_loss: 4.4518 - val_acc: 0.1342\n",
      "\n",
      "Epoch 00011: val_loss improved from 4.48237 to 4.45176, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 12/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 4.2419 - acc: 0.1873 - val_loss: 4.3960 - val_acc: 0.1337\n",
      "\n",
      "Epoch 00012: val_loss improved from 4.45176 to 4.39596, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 13/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 4.1884 - acc: 0.1942 - val_loss: 4.3690 - val_acc: 0.1380\n",
      "\n",
      "Epoch 00013: val_loss improved from 4.39596 to 4.36904, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 14/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 4.1381 - acc: 0.2007 - val_loss: 4.3111 - val_acc: 0.1444\n",
      "\n",
      "Epoch 00014: val_loss improved from 4.36904 to 4.31110, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 15/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 4.0639 - acc: 0.2265 - val_loss: 4.2674 - val_acc: 0.1618\n",
      "\n",
      "Epoch 00015: val_loss improved from 4.31110 to 4.26736, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 16/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 4.0262 - acc: 0.2265 - val_loss: 4.2310 - val_acc: 0.1721\n",
      "\n",
      "Epoch 00016: val_loss improved from 4.26736 to 4.23097, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 17/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.9750 - acc: 0.2323 - val_loss: 4.1918 - val_acc: 0.1746\n",
      "\n",
      "Epoch 00017: val_loss improved from 4.23097 to 4.19181, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 18/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.9252 - acc: 0.2469 - val_loss: 4.1680 - val_acc: 0.1759\n",
      "\n",
      "Epoch 00018: val_loss improved from 4.19181 to 4.16795, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 19/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.8918 - acc: 0.2462 - val_loss: 4.1457 - val_acc: 0.1661\n",
      "\n",
      "Epoch 00019: val_loss improved from 4.16795 to 4.14569, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 20/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 3.8311 - acc: 0.2589 - val_loss: 4.1067 - val_acc: 0.1810\n",
      "\n",
      "Epoch 00020: val_loss improved from 4.14569 to 4.10669, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 21/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.7951 - acc: 0.2655 - val_loss: 4.0773 - val_acc: 0.1806\n",
      "\n",
      "Epoch 00021: val_loss improved from 4.10669 to 4.07734, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 22/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.7467 - acc: 0.2770 - val_loss: 4.0374 - val_acc: 0.1921\n",
      "\n",
      "Epoch 00022: val_loss improved from 4.07734 to 4.03735, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 23/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.7135 - acc: 0.2862 - val_loss: 4.0137 - val_acc: 0.1942\n",
      "\n",
      "Epoch 00023: val_loss improved from 4.03735 to 4.01369, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 24/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.6727 - acc: 0.2838 - val_loss: 3.9616 - val_acc: 0.2032\n",
      "\n",
      "Epoch 00024: val_loss improved from 4.01369 to 3.96162, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 25/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.6258 - acc: 0.2909 - val_loss: 3.9820 - val_acc: 0.2002\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.96162\n",
      "Epoch 26/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 3.5962 - acc: 0.2991 - val_loss: 3.9300 - val_acc: 0.2108\n",
      "\n",
      "Epoch 00026: val_loss improved from 3.96162 to 3.92998, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 27/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.5543 - acc: 0.3042 - val_loss: 3.9190 - val_acc: 0.2074\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.92998 to 3.91898, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 28/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.5171 - acc: 0.3170 - val_loss: 3.8956 - val_acc: 0.2066\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.91898 to 3.89558, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 29/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.5066 - acc: 0.3178 - val_loss: 3.8678 - val_acc: 0.2083\n",
      "\n",
      "Epoch 00029: val_loss improved from 3.89558 to 3.86780, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 30/1000\n",
      "182/182 [==============================] - 137s 751ms/step - loss: 3.4580 - acc: 0.3254 - val_loss: 3.8462 - val_acc: 0.2227\n",
      "\n",
      "Epoch 00030: val_loss improved from 3.86780 to 3.84619, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 31/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 3.4373 - acc: 0.3261 - val_loss: 3.8029 - val_acc: 0.2185\n",
      "\n",
      "Epoch 00031: val_loss improved from 3.84619 to 3.80294, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 136s 748ms/step - loss: 3.4132 - acc: 0.3271 - val_loss: 3.7882 - val_acc: 0.2244\n",
      "\n",
      "Epoch 00032: val_loss improved from 3.80294 to 3.78816, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 33/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.3830 - acc: 0.3379 - val_loss: 3.7879 - val_acc: 0.2176\n",
      "\n",
      "Epoch 00033: val_loss improved from 3.78816 to 3.78788, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 34/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.3363 - acc: 0.3429 - val_loss: 3.7904 - val_acc: 0.2078\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.78788\n",
      "Epoch 35/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.3099 - acc: 0.3431 - val_loss: 3.7527 - val_acc: 0.2308\n",
      "\n",
      "Epoch 00035: val_loss improved from 3.78788 to 3.75272, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 36/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.2909 - acc: 0.3584 - val_loss: 3.7373 - val_acc: 0.2385\n",
      "\n",
      "Epoch 00036: val_loss improved from 3.75272 to 3.73727, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 37/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.2654 - acc: 0.3547 - val_loss: 3.7157 - val_acc: 0.2402\n",
      "\n",
      "Epoch 00037: val_loss improved from 3.73727 to 3.71574, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 38/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.2384 - acc: 0.3547 - val_loss: 3.7053 - val_acc: 0.2385\n",
      "\n",
      "Epoch 00038: val_loss improved from 3.71574 to 3.70535, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 39/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 3.2298 - acc: 0.3587 - val_loss: 3.6723 - val_acc: 0.2496\n",
      "\n",
      "Epoch 00039: val_loss improved from 3.70535 to 3.67226, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 40/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 3.1786 - acc: 0.3757 - val_loss: 3.6658 - val_acc: 0.2513\n",
      "\n",
      "Epoch 00040: val_loss improved from 3.67226 to 3.66577, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 41/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.1514 - acc: 0.3807 - val_loss: 3.6408 - val_acc: 0.2453\n",
      "\n",
      "Epoch 00041: val_loss improved from 3.66577 to 3.64079, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 42/1000\n",
      "182/182 [==============================] - 137s 750ms/step - loss: 3.1424 - acc: 0.3726 - val_loss: 3.6405 - val_acc: 0.2483\n",
      "\n",
      "Epoch 00042: val_loss improved from 3.64079 to 3.64053, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 43/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 3.1244 - acc: 0.3767 - val_loss: 3.6322 - val_acc: 0.2415\n",
      "\n",
      "Epoch 00043: val_loss improved from 3.64053 to 3.63224, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 44/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.0860 - acc: 0.3899 - val_loss: 3.6095 - val_acc: 0.2359\n",
      "\n",
      "Epoch 00044: val_loss improved from 3.63224 to 3.60946, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 45/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.0736 - acc: 0.3853 - val_loss: 3.5998 - val_acc: 0.2479\n",
      "\n",
      "Epoch 00045: val_loss improved from 3.60946 to 3.59978, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 46/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 3.0429 - acc: 0.3963 - val_loss: 3.5622 - val_acc: 0.2551\n",
      "\n",
      "Epoch 00046: val_loss improved from 3.59978 to 3.56217, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 47/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 3.0192 - acc: 0.3992 - val_loss: 3.5429 - val_acc: 0.2538\n",
      "\n",
      "Epoch 00047: val_loss improved from 3.56217 to 3.54286, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 48/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.9999 - acc: 0.3997 - val_loss: 3.5477 - val_acc: 0.2645\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 3.54286\n",
      "Epoch 49/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.9830 - acc: 0.4035 - val_loss: 3.5223 - val_acc: 0.2645\n",
      "\n",
      "Epoch 00049: val_loss improved from 3.54286 to 3.52232, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 50/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.9606 - acc: 0.4023 - val_loss: 3.5056 - val_acc: 0.2709\n",
      "\n",
      "Epoch 00050: val_loss improved from 3.52232 to 3.50555, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 51/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.9485 - acc: 0.4003 - val_loss: 3.4998 - val_acc: 0.2692\n",
      "\n",
      "Epoch 00051: val_loss improved from 3.50555 to 3.49981, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 52/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.9225 - acc: 0.4102 - val_loss: 3.5108 - val_acc: 0.2636\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 3.49981\n",
      "Epoch 53/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.8884 - acc: 0.4169 - val_loss: 3.5150 - val_acc: 0.2547\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 3.49981\n",
      "Epoch 54/1000\n",
      "182/182 [==============================] - 136s 746ms/step - loss: 2.8909 - acc: 0.4166 - val_loss: 3.4909 - val_acc: 0.2636\n",
      "\n",
      "Epoch 00054: val_loss improved from 3.49981 to 3.49093, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 55/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.8723 - acc: 0.4191 - val_loss: 3.4713 - val_acc: 0.2777\n",
      "\n",
      "Epoch 00055: val_loss improved from 3.49093 to 3.47131, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 56/1000\n",
      "182/182 [==============================] - 138s 761ms/step - loss: 2.8467 - acc: 0.4263 - val_loss: 3.4581 - val_acc: 0.2658\n",
      "\n",
      "Epoch 00056: val_loss improved from 3.47131 to 3.45811, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 57/1000\n",
      "182/182 [==============================] - 137s 751ms/step - loss: 2.8287 - acc: 0.4231 - val_loss: 3.4265 - val_acc: 0.2658\n",
      "\n",
      "Epoch 00057: val_loss improved from 3.45811 to 3.42648, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 58/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.8262 - acc: 0.4188 - val_loss: 3.4160 - val_acc: 0.2751\n",
      "\n",
      "Epoch 00058: val_loss improved from 3.42648 to 3.41605, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 59/1000\n",
      "182/182 [==============================] - 137s 750ms/step - loss: 2.7994 - acc: 0.4322 - val_loss: 3.4239 - val_acc: 0.2764\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 3.41605\n",
      "Epoch 60/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.7754 - acc: 0.4358 - val_loss: 3.4027 - val_acc: 0.2730\n",
      "\n",
      "Epoch 00060: val_loss improved from 3.41605 to 3.40269, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 61/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.7601 - acc: 0.4399 - val_loss: 3.4072 - val_acc: 0.2743\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 3.40269\n",
      "Epoch 62/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.7613 - acc: 0.4394 - val_loss: 3.3913 - val_acc: 0.2828\n",
      "\n",
      "Epoch 00062: val_loss improved from 3.40269 to 3.39135, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 63/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.7323 - acc: 0.4447 - val_loss: 3.3347 - val_acc: 0.2875\n",
      "\n",
      "Epoch 00063: val_loss improved from 3.39135 to 3.33467, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 64/1000\n",
      "182/182 [==============================] - 137s 752ms/step - loss: 2.7372 - acc: 0.4358 - val_loss: 3.3750 - val_acc: 0.2696\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 3.33467\n",
      "Epoch 65/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 2.6983 - acc: 0.4404 - val_loss: 3.3641 - val_acc: 0.2862\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 3.33467\n",
      "Epoch 66/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 136s 747ms/step - loss: 2.6871 - acc: 0.4437 - val_loss: 3.3675 - val_acc: 0.2866\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 3.33467\n",
      "Epoch 67/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.6630 - acc: 0.4572 - val_loss: 3.3386 - val_acc: 0.2875\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 3.33467\n",
      "Epoch 68/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 2.6582 - acc: 0.4473 - val_loss: 3.3504 - val_acc: 0.2819\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 3.33467\n",
      "Epoch 69/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.6584 - acc: 0.4511 - val_loss: 3.2939 - val_acc: 0.3007\n",
      "\n",
      "Epoch 00069: val_loss improved from 3.33467 to 3.29387, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 70/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.6402 - acc: 0.4528 - val_loss: 3.3209 - val_acc: 0.2807\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 3.29387\n",
      "Epoch 71/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.6355 - acc: 0.4499 - val_loss: 3.2956 - val_acc: 0.2943\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 3.29387\n",
      "Epoch 72/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.5935 - acc: 0.4679 - val_loss: 3.2875 - val_acc: 0.2853\n",
      "\n",
      "Epoch 00072: val_loss improved from 3.29387 to 3.28752, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 73/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.5742 - acc: 0.4615 - val_loss: 3.2469 - val_acc: 0.3075\n",
      "\n",
      "Epoch 00073: val_loss improved from 3.28752 to 3.24691, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 74/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.5728 - acc: 0.4693 - val_loss: 3.2811 - val_acc: 0.2905\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 3.24691\n",
      "Epoch 75/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.5747 - acc: 0.4590 - val_loss: 3.2605 - val_acc: 0.2939\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 3.24691\n",
      "Epoch 76/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.5559 - acc: 0.4753 - val_loss: 3.2631 - val_acc: 0.2909\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 3.24691\n",
      "Epoch 77/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.5542 - acc: 0.4687 - val_loss: 3.2582 - val_acc: 0.2973\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 3.24691\n",
      "Epoch 78/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.5167 - acc: 0.4749 - val_loss: 3.2245 - val_acc: 0.2986\n",
      "\n",
      "Epoch 00078: val_loss improved from 3.24691 to 3.22451, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 79/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.5088 - acc: 0.4782 - val_loss: 3.2268 - val_acc: 0.3032\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 3.22451\n",
      "Epoch 80/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 2.5013 - acc: 0.4809 - val_loss: 3.2435 - val_acc: 0.3088\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 3.22451\n",
      "Epoch 81/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.4737 - acc: 0.4895 - val_loss: 3.2240 - val_acc: 0.3041\n",
      "\n",
      "Epoch 00081: val_loss improved from 3.22451 to 3.22402, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 82/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.4734 - acc: 0.4859 - val_loss: 3.2011 - val_acc: 0.3032\n",
      "\n",
      "Epoch 00082: val_loss improved from 3.22402 to 3.20113, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 83/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.4613 - acc: 0.4885 - val_loss: 3.2207 - val_acc: 0.3054\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 3.20113\n",
      "Epoch 84/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.4513 - acc: 0.4861 - val_loss: 3.1810 - val_acc: 0.3126\n",
      "\n",
      "Epoch 00084: val_loss improved from 3.20113 to 3.18102, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 85/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 2.4610 - acc: 0.4830 - val_loss: 3.1770 - val_acc: 0.3020\n",
      "\n",
      "Epoch 00085: val_loss improved from 3.18102 to 3.17704, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 86/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.4266 - acc: 0.4933 - val_loss: 3.1798 - val_acc: 0.2986\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 3.17704\n",
      "Epoch 87/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.4249 - acc: 0.4887 - val_loss: 3.1918 - val_acc: 0.3003\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 3.17704\n",
      "Epoch 88/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.4077 - acc: 0.5022 - val_loss: 3.1838 - val_acc: 0.3113\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 3.17704\n",
      "Epoch 89/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3880 - acc: 0.5015 - val_loss: 3.1554 - val_acc: 0.3075\n",
      "\n",
      "Epoch 00089: val_loss improved from 3.17704 to 3.15542, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 90/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3873 - acc: 0.5015 - val_loss: 3.1402 - val_acc: 0.3173\n",
      "\n",
      "Epoch 00090: val_loss improved from 3.15542 to 3.14025, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 91/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.3838 - acc: 0.4894 - val_loss: 3.1557 - val_acc: 0.3113\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 3.14025\n",
      "Epoch 92/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.3732 - acc: 0.4998 - val_loss: 3.1396 - val_acc: 0.3241\n",
      "\n",
      "Epoch 00092: val_loss improved from 3.14025 to 3.13955, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 93/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3573 - acc: 0.5072 - val_loss: 3.1303 - val_acc: 0.3220\n",
      "\n",
      "Epoch 00093: val_loss improved from 3.13955 to 3.13034, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 94/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3469 - acc: 0.5088 - val_loss: 3.1400 - val_acc: 0.3173\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 3.13034\n",
      "Epoch 95/1000\n",
      "182/182 [==============================] - 137s 753ms/step - loss: 2.3179 - acc: 0.5199 - val_loss: 3.1447 - val_acc: 0.3092\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 3.13034\n",
      "Epoch 96/1000\n",
      "182/182 [==============================] - 137s 750ms/step - loss: 2.3235 - acc: 0.5113 - val_loss: 3.1228 - val_acc: 0.3135\n",
      "\n",
      "Epoch 00096: val_loss improved from 3.13034 to 3.12285, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 97/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3176 - acc: 0.5137 - val_loss: 3.1024 - val_acc: 0.3279\n",
      "\n",
      "Epoch 00097: val_loss improved from 3.12285 to 3.10245, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 98/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.3131 - acc: 0.5160 - val_loss: 3.0939 - val_acc: 0.3207\n",
      "\n",
      "Epoch 00098: val_loss improved from 3.10245 to 3.09387, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 99/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.2959 - acc: 0.5079 - val_loss: 3.1109 - val_acc: 0.3198\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 3.09387\n",
      "Epoch 100/1000\n",
      "182/182 [==============================] - 136s 748ms/step - loss: 2.2952 - acc: 0.5239 - val_loss: 3.1276 - val_acc: 0.3164\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 3.09387\n",
      "Epoch 101/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 2.2755 - acc: 0.5252 - val_loss: 3.0939 - val_acc: 0.3288\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 3.09387\n",
      "Epoch 102/1000\n",
      "182/182 [==============================] - 139s 766ms/step - loss: 2.2626 - acc: 0.5198 - val_loss: 3.0896 - val_acc: 0.3220\n",
      "\n",
      "Epoch 00102: val_loss improved from 3.09387 to 3.08963, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 136s 748ms/step - loss: 2.2635 - acc: 0.5180 - val_loss: 3.0891 - val_acc: 0.3143\n",
      "\n",
      "Epoch 00103: val_loss improved from 3.08963 to 3.08913, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 104/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.2477 - acc: 0.5170 - val_loss: 3.0467 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00104: val_loss improved from 3.08913 to 3.04673, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 105/1000\n",
      "182/182 [==============================] - 136s 750ms/step - loss: 2.2493 - acc: 0.5170 - val_loss: 3.0633 - val_acc: 0.3147\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 3.04673\n",
      "Epoch 106/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.2269 - acc: 0.5228 - val_loss: 3.0944 - val_acc: 0.3250\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 3.04673\n",
      "Epoch 107/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.2239 - acc: 0.5261 - val_loss: 3.0687 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 3.04673\n",
      "Epoch 108/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.2054 - acc: 0.5278 - val_loss: 3.0516 - val_acc: 0.3326\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 3.04673\n",
      "Epoch 109/1000\n",
      "182/182 [==============================] - 137s 753ms/step - loss: 2.1940 - acc: 0.5271 - val_loss: 3.0739 - val_acc: 0.3262\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 3.04673\n",
      "Epoch 110/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 2.1858 - acc: 0.5379 - val_loss: 3.0274 - val_acc: 0.3322\n",
      "\n",
      "Epoch 00110: val_loss improved from 3.04673 to 3.02738, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 111/1000\n",
      "182/182 [==============================] - 147s 807ms/step - loss: 2.1836 - acc: 0.5369 - val_loss: 3.0527 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 3.02738\n",
      "Epoch 112/1000\n",
      "182/182 [==============================] - 149s 819ms/step - loss: 2.1723 - acc: 0.5362 - val_loss: 3.0681 - val_acc: 0.3237\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 3.02738\n",
      "Epoch 113/1000\n",
      "182/182 [==============================] - 150s 821ms/step - loss: 2.1733 - acc: 0.5345 - val_loss: 3.0097 - val_acc: 0.3403\n",
      "\n",
      "Epoch 00113: val_loss improved from 3.02738 to 3.00965, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 114/1000\n",
      "182/182 [==============================] - 145s 799ms/step - loss: 2.1521 - acc: 0.5400 - val_loss: 3.0329 - val_acc: 0.3224\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 3.00965\n",
      "Epoch 115/1000\n",
      "182/182 [==============================] - 147s 809ms/step - loss: 2.1723 - acc: 0.5338 - val_loss: 3.0315 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 3.00965\n",
      "Epoch 116/1000\n",
      "182/182 [==============================] - 146s 805ms/step - loss: 2.1249 - acc: 0.5491 - val_loss: 3.0362 - val_acc: 0.3228\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 3.00965\n",
      "Epoch 117/1000\n",
      "182/182 [==============================] - 143s 786ms/step - loss: 2.1261 - acc: 0.5428 - val_loss: 3.0044 - val_acc: 0.3403\n",
      "\n",
      "Epoch 00117: val_loss improved from 3.00965 to 3.00438, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 118/1000\n",
      "182/182 [==============================] - 150s 823ms/step - loss: 2.1141 - acc: 0.5527 - val_loss: 3.0160 - val_acc: 0.3309\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 3.00438\n",
      "Epoch 119/1000\n",
      "182/182 [==============================] - 141s 777ms/step - loss: 2.1155 - acc: 0.5419 - val_loss: 2.9944 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00119: val_loss improved from 3.00438 to 2.99438, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 120/1000\n",
      "182/182 [==============================] - 146s 803ms/step - loss: 2.1185 - acc: 0.5450 - val_loss: 3.0190 - val_acc: 0.3279\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2.99438\n",
      "Epoch 121/1000\n",
      "182/182 [==============================] - 151s 828ms/step - loss: 2.1375 - acc: 0.5416 - val_loss: 3.0049 - val_acc: 0.3348\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 2.99438\n",
      "Epoch 122/1000\n",
      "182/182 [==============================] - 152s 833ms/step - loss: 2.1217 - acc: 0.5469 - val_loss: 3.0077 - val_acc: 0.3365\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 2.99438\n",
      "Epoch 123/1000\n",
      "182/182 [==============================] - 153s 838ms/step - loss: 2.0865 - acc: 0.5522 - val_loss: 3.0026 - val_acc: 0.3318\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2.99438\n",
      "Epoch 124/1000\n",
      "182/182 [==============================] - 152s 835ms/step - loss: 2.0584 - acc: 0.5555 - val_loss: 2.9935 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00124: val_loss improved from 2.99438 to 2.99351, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 125/1000\n",
      "182/182 [==============================] - 150s 822ms/step - loss: 2.0658 - acc: 0.5496 - val_loss: 2.9802 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00125: val_loss improved from 2.99351 to 2.98024, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 126/1000\n",
      "182/182 [==============================] - 149s 818ms/step - loss: 2.0345 - acc: 0.5637 - val_loss: 3.0066 - val_acc: 0.3394\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2.98024\n",
      "Epoch 127/1000\n",
      "182/182 [==============================] - 152s 837ms/step - loss: 2.0455 - acc: 0.5551 - val_loss: 2.9693 - val_acc: 0.3352\n",
      "\n",
      "Epoch 00127: val_loss improved from 2.98024 to 2.96932, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 128/1000\n",
      "182/182 [==============================] - 161s 886ms/step - loss: 2.0670 - acc: 0.5529 - val_loss: 2.9526 - val_acc: 0.3437\n",
      "\n",
      "Epoch 00128: val_loss improved from 2.96932 to 2.95257, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 129/1000\n",
      "182/182 [==============================] - 161s 885ms/step - loss: 2.0463 - acc: 0.5531 - val_loss: 2.9782 - val_acc: 0.3382\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2.95257\n",
      "Epoch 130/1000\n",
      "182/182 [==============================] - 160s 877ms/step - loss: 2.0143 - acc: 0.5565 - val_loss: 2.9424 - val_acc: 0.3497\n",
      "\n",
      "Epoch 00130: val_loss improved from 2.95257 to 2.94240, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 131/1000\n",
      "182/182 [==============================] - 159s 874ms/step - loss: 2.0269 - acc: 0.5555 - val_loss: 2.9257 - val_acc: 0.3420\n",
      "\n",
      "Epoch 00131: val_loss improved from 2.94240 to 2.92567, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 132/1000\n",
      "182/182 [==============================] - 162s 892ms/step - loss: 2.0092 - acc: 0.5706 - val_loss: 2.9508 - val_acc: 0.3416\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2.92567\n",
      "Epoch 133/1000\n",
      "182/182 [==============================] - 165s 905ms/step - loss: 2.0145 - acc: 0.5630 - val_loss: 2.9582 - val_acc: 0.3416\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2.92567\n",
      "Epoch 134/1000\n",
      "182/182 [==============================] - 152s 837ms/step - loss: 2.0016 - acc: 0.5651 - val_loss: 2.9185 - val_acc: 0.3480\n",
      "\n",
      "Epoch 00134: val_loss improved from 2.92567 to 2.91850, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 135/1000\n",
      "182/182 [==============================] - 155s 854ms/step - loss: 2.0095 - acc: 0.5639 - val_loss: 2.9238 - val_acc: 0.3463\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2.91850\n",
      "Epoch 136/1000\n",
      "182/182 [==============================] - 153s 843ms/step - loss: 2.0239 - acc: 0.5591 - val_loss: 2.9411 - val_acc: 0.3386\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2.91850\n",
      "Epoch 137/1000\n",
      "182/182 [==============================] - 153s 839ms/step - loss: 1.9940 - acc: 0.5658 - val_loss: 2.9859 - val_acc: 0.3271\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2.91850\n",
      "Epoch 138/1000\n",
      "182/182 [==============================] - 154s 845ms/step - loss: 1.9910 - acc: 0.5776 - val_loss: 2.9175 - val_acc: 0.3467\n",
      "\n",
      "Epoch 00138: val_loss improved from 2.91850 to 2.91752, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 139/1000\n",
      "182/182 [==============================] - 152s 836ms/step - loss: 1.9724 - acc: 0.5706 - val_loss: 2.9305 - val_acc: 0.3463\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2.91752\n",
      "Epoch 140/1000\n",
      "182/182 [==============================] - 146s 800ms/step - loss: 1.9774 - acc: 0.5702 - val_loss: 2.9141 - val_acc: 0.3441\n",
      "\n",
      "Epoch 00140: val_loss improved from 2.91752 to 2.91409, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 147s 806ms/step - loss: 1.9696 - acc: 0.5714 - val_loss: 2.9442 - val_acc: 0.3497\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2.91409\n",
      "Epoch 142/1000\n",
      "182/182 [==============================] - 143s 787ms/step - loss: 1.9701 - acc: 0.5731 - val_loss: 2.9295 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 2.91409\n",
      "Epoch 143/1000\n",
      "182/182 [==============================] - 137s 752ms/step - loss: 1.9513 - acc: 0.5699 - val_loss: 2.9057 - val_acc: 0.3526\n",
      "\n",
      "Epoch 00143: val_loss improved from 2.91409 to 2.90568, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 144/1000\n",
      "182/182 [==============================] - 141s 773ms/step - loss: 1.9452 - acc: 0.5668 - val_loss: 2.8931 - val_acc: 0.3612\n",
      "\n",
      "Epoch 00144: val_loss improved from 2.90568 to 2.89313, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 145/1000\n",
      "182/182 [==============================] - 137s 753ms/step - loss: 1.9444 - acc: 0.5740 - val_loss: 2.8906 - val_acc: 0.3505\n",
      "\n",
      "Epoch 00145: val_loss improved from 2.89313 to 2.89056, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 146/1000\n",
      "182/182 [==============================] - 136s 749ms/step - loss: 1.9340 - acc: 0.5762 - val_loss: 2.9235 - val_acc: 0.3360\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2.89056\n",
      "Epoch 147/1000\n",
      "182/182 [==============================] - 136s 747ms/step - loss: 1.9139 - acc: 0.5738 - val_loss: 2.8949 - val_acc: 0.3578\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2.89056\n",
      "Epoch 148/1000\n",
      "182/182 [==============================] - 141s 773ms/step - loss: 1.9234 - acc: 0.5778 - val_loss: 2.8923 - val_acc: 0.3552\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2.89056\n",
      "Epoch 149/1000\n",
      "182/182 [==============================] - 140s 767ms/step - loss: 1.9169 - acc: 0.5817 - val_loss: 2.9185 - val_acc: 0.3467\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2.89056\n",
      "Epoch 150/1000\n",
      "182/182 [==============================] - 142s 778ms/step - loss: 1.9052 - acc: 0.5827 - val_loss: 2.8973 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2.89056\n",
      "Epoch 151/1000\n",
      "182/182 [==============================] - 135s 739ms/step - loss: 1.9104 - acc: 0.5910 - val_loss: 2.9054 - val_acc: 0.3475\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 2.89056\n",
      "Epoch 152/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.9026 - acc: 0.5817 - val_loss: 2.8861 - val_acc: 0.3641\n",
      "\n",
      "Epoch 00152: val_loss improved from 2.89056 to 2.88612, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 153/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.9051 - acc: 0.5831 - val_loss: 2.8781 - val_acc: 0.3492\n",
      "\n",
      "Epoch 00153: val_loss improved from 2.88612 to 2.87811, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 154/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8903 - acc: 0.5841 - val_loss: 2.8923 - val_acc: 0.3441\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 2.87811\n",
      "Epoch 155/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.9006 - acc: 0.5812 - val_loss: 2.8895 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 2.87811\n",
      "Epoch 156/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.9052 - acc: 0.5783 - val_loss: 2.8727 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00156: val_loss improved from 2.87811 to 2.87266, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 157/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8814 - acc: 0.5836 - val_loss: 2.8714 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00157: val_loss improved from 2.87266 to 2.87143, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 158/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8686 - acc: 0.5888 - val_loss: 2.8595 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00158: val_loss improved from 2.87143 to 2.85952, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 159/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.8806 - acc: 0.5893 - val_loss: 2.8635 - val_acc: 0.3590\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 2.85952\n",
      "Epoch 160/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8597 - acc: 0.5886 - val_loss: 2.8504 - val_acc: 0.3663\n",
      "\n",
      "Epoch 00160: val_loss improved from 2.85952 to 2.85039, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 161/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.8704 - acc: 0.5852 - val_loss: 2.8825 - val_acc: 0.3556\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 2.85039\n",
      "Epoch 162/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8455 - acc: 0.5920 - val_loss: 2.8570 - val_acc: 0.3688\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 2.85039\n",
      "Epoch 163/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8496 - acc: 0.5850 - val_loss: 2.8531 - val_acc: 0.3569\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 2.85039\n",
      "Epoch 164/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.8280 - acc: 0.5965 - val_loss: 2.8343 - val_acc: 0.3667\n",
      "\n",
      "Epoch 00164: val_loss improved from 2.85039 to 2.83426, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 165/1000\n",
      "182/182 [==============================] - 134s 736ms/step - loss: 1.8084 - acc: 0.6006 - val_loss: 2.8840 - val_acc: 0.3560\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 2.83426\n",
      "Epoch 166/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.8181 - acc: 0.5963 - val_loss: 2.8456 - val_acc: 0.3658\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 2.83426\n",
      "Epoch 167/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.8529 - acc: 0.5898 - val_loss: 2.8630 - val_acc: 0.3607\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 2.83426\n",
      "Epoch 168/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8245 - acc: 0.5982 - val_loss: 2.8588 - val_acc: 0.3526\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 2.83426\n",
      "Epoch 169/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.8092 - acc: 0.5991 - val_loss: 2.8512 - val_acc: 0.3680\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 2.83426\n",
      "Epoch 170/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.7955 - acc: 0.5986 - val_loss: 2.8380 - val_acc: 0.3548\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 2.83426\n",
      "Epoch 171/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.8141 - acc: 0.5938 - val_loss: 2.8445 - val_acc: 0.3616\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 2.83426\n",
      "Epoch 172/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.8006 - acc: 0.5968 - val_loss: 2.8479 - val_acc: 0.3616\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 2.83426\n",
      "Epoch 173/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.7765 - acc: 0.6063 - val_loss: 2.8192 - val_acc: 0.3744\n",
      "\n",
      "Epoch 00173: val_loss improved from 2.83426 to 2.81920, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 174/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.7942 - acc: 0.6001 - val_loss: 2.8332 - val_acc: 0.3514\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 2.81920\n",
      "Epoch 175/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.7794 - acc: 0.6085 - val_loss: 2.8198 - val_acc: 0.3629\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 2.81920\n",
      "Epoch 176/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.7727 - acc: 0.6015 - val_loss: 2.8354 - val_acc: 0.3697\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 2.81920\n",
      "Epoch 177/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7513 - acc: 0.6125 - val_loss: 2.8223 - val_acc: 0.3582\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 2.81920\n",
      "Epoch 178/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.7721 - acc: 0.6035 - val_loss: 2.8064 - val_acc: 0.3646\n",
      "\n",
      "Epoch 00178: val_loss improved from 2.81920 to 2.80639, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 179/1000\n",
      "182/182 [==============================] - 134s 735ms/step - loss: 1.7850 - acc: 0.6011 - val_loss: 2.8154 - val_acc: 0.3744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00179: val_loss did not improve from 2.80639\n",
      "Epoch 180/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.7567 - acc: 0.6087 - val_loss: 2.8263 - val_acc: 0.3705\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 2.80639\n",
      "Epoch 181/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7538 - acc: 0.6075 - val_loss: 2.7963 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00181: val_loss improved from 2.80639 to 2.79626, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 182/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.7602 - acc: 0.6104 - val_loss: 2.7917 - val_acc: 0.3722\n",
      "\n",
      "Epoch 00182: val_loss improved from 2.79626 to 2.79166, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 183/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7477 - acc: 0.5981 - val_loss: 2.8059 - val_acc: 0.3663\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 2.79166\n",
      "Epoch 184/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7511 - acc: 0.6090 - val_loss: 2.8076 - val_acc: 0.3624\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 2.79166\n",
      "Epoch 185/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.7355 - acc: 0.6020 - val_loss: 2.7898 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00185: val_loss improved from 2.79166 to 2.78978, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 186/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.7220 - acc: 0.6156 - val_loss: 2.8071 - val_acc: 0.3650\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 2.78978\n",
      "Epoch 187/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.7342 - acc: 0.6178 - val_loss: 2.7845 - val_acc: 0.3671\n",
      "\n",
      "Epoch 00187: val_loss improved from 2.78978 to 2.78446, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 188/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7148 - acc: 0.6155 - val_loss: 2.7745 - val_acc: 0.3633\n",
      "\n",
      "Epoch 00188: val_loss improved from 2.78446 to 2.77449, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 189/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7224 - acc: 0.6154 - val_loss: 2.7919 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 2.77449\n",
      "Epoch 190/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7259 - acc: 0.6054 - val_loss: 2.7948 - val_acc: 0.3722\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 2.77449\n",
      "Epoch 191/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7073 - acc: 0.6152 - val_loss: 2.7876 - val_acc: 0.3722\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 2.77449\n",
      "Epoch 192/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.7193 - acc: 0.6181 - val_loss: 2.7871 - val_acc: 0.3658\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 2.77449\n",
      "Epoch 193/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6974 - acc: 0.6168 - val_loss: 2.7739 - val_acc: 0.3833\n",
      "\n",
      "Epoch 00193: val_loss improved from 2.77449 to 2.77389, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 194/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6862 - acc: 0.6253 - val_loss: 2.7756 - val_acc: 0.3786\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 2.77389\n",
      "Epoch 195/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.6910 - acc: 0.6211 - val_loss: 2.8209 - val_acc: 0.3693\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 2.77389\n",
      "Epoch 196/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.6989 - acc: 0.6207 - val_loss: 2.7453 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00196: val_loss improved from 2.77389 to 2.74529, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 197/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6879 - acc: 0.6197 - val_loss: 2.7863 - val_acc: 0.3667\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 2.74529\n",
      "Epoch 198/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6681 - acc: 0.6212 - val_loss: 2.8016 - val_acc: 0.3735\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 2.74529\n",
      "Epoch 199/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6852 - acc: 0.6240 - val_loss: 2.7688 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 2.74529\n",
      "Epoch 200/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6738 - acc: 0.6228 - val_loss: 2.7501 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 2.74529\n",
      "Epoch 201/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.6375 - acc: 0.6295 - val_loss: 2.7813 - val_acc: 0.3752\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 2.74529\n",
      "Epoch 202/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6766 - acc: 0.6200 - val_loss: 2.7544 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 2.74529\n",
      "Epoch 203/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6863 - acc: 0.6228 - val_loss: 2.7494 - val_acc: 0.3795\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 2.74529\n",
      "Epoch 204/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6857 - acc: 0.6114 - val_loss: 2.7598 - val_acc: 0.3786\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 2.74529\n",
      "Epoch 205/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.6636 - acc: 0.6229 - val_loss: 2.7917 - val_acc: 0.3710\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 2.74529\n",
      "Epoch 206/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.6622 - acc: 0.6221 - val_loss: 2.7603 - val_acc: 0.3756\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 2.74529\n",
      "Epoch 207/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6495 - acc: 0.6303 - val_loss: 2.7522 - val_acc: 0.3688\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 2.74529\n",
      "Epoch 208/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.6602 - acc: 0.6267 - val_loss: 2.7591 - val_acc: 0.3731\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 2.74529\n",
      "Epoch 209/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.6457 - acc: 0.6229 - val_loss: 2.7505 - val_acc: 0.3705\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 2.74529\n",
      "Epoch 210/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6198 - acc: 0.6286 - val_loss: 2.7314 - val_acc: 0.3761\n",
      "\n",
      "Epoch 00210: val_loss improved from 2.74529 to 2.73137, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 211/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6372 - acc: 0.6343 - val_loss: 2.7508 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 2.73137\n",
      "Epoch 212/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6427 - acc: 0.6186 - val_loss: 2.7599 - val_acc: 0.3675\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 2.73137\n",
      "Epoch 213/1000\n",
      "182/182 [==============================] - 134s 735ms/step - loss: 1.6303 - acc: 0.6252 - val_loss: 2.7309 - val_acc: 0.3752\n",
      "\n",
      "Epoch 00213: val_loss improved from 2.73137 to 2.73093, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 214/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.6185 - acc: 0.6264 - val_loss: 2.7633 - val_acc: 0.3897\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 2.73093\n",
      "Epoch 215/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6269 - acc: 0.6272 - val_loss: 2.7469 - val_acc: 0.3761\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 2.73093\n",
      "Epoch 216/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.5902 - acc: 0.6410 - val_loss: 2.7650 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 2.73093\n",
      "Epoch 217/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.6143 - acc: 0.6305 - val_loss: 2.7486 - val_acc: 0.3833\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 2.73093\n",
      "Epoch 218/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.6264 - acc: 0.6293 - val_loss: 2.7493 - val_acc: 0.3799\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 2.73093\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 133s 730ms/step - loss: 1.6132 - acc: 0.6291 - val_loss: 2.7100 - val_acc: 0.3880\n",
      "\n",
      "Epoch 00219: val_loss improved from 2.73093 to 2.70998, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 220/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.6054 - acc: 0.6350 - val_loss: 2.7430 - val_acc: 0.3637\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 2.70998\n",
      "Epoch 221/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.6176 - acc: 0.6326 - val_loss: 2.7283 - val_acc: 0.3931\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 2.70998\n",
      "Epoch 222/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5857 - acc: 0.6403 - val_loss: 2.7193 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 2.70998\n",
      "Epoch 223/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5883 - acc: 0.6380 - val_loss: 2.7453 - val_acc: 0.3701\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 2.70998\n",
      "Epoch 224/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5806 - acc: 0.6332 - val_loss: 2.7061 - val_acc: 0.3927\n",
      "\n",
      "Epoch 00224: val_loss improved from 2.70998 to 2.70611, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 225/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5912 - acc: 0.6375 - val_loss: 2.7238 - val_acc: 0.3799\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 2.70611\n",
      "Epoch 226/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5873 - acc: 0.6413 - val_loss: 2.7249 - val_acc: 0.3833\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 2.70611\n",
      "Epoch 227/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5721 - acc: 0.6369 - val_loss: 2.7227 - val_acc: 0.3799\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 2.70611\n",
      "Epoch 228/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5693 - acc: 0.6435 - val_loss: 2.7465 - val_acc: 0.3773\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 2.70611\n",
      "Epoch 229/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5696 - acc: 0.6370 - val_loss: 2.7342 - val_acc: 0.3752\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 2.70611\n",
      "Epoch 230/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5744 - acc: 0.6377 - val_loss: 2.6916 - val_acc: 0.3935\n",
      "\n",
      "Epoch 00230: val_loss improved from 2.70611 to 2.69156, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 231/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5726 - acc: 0.6444 - val_loss: 2.7279 - val_acc: 0.3786\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 2.69156\n",
      "Epoch 232/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.5795 - acc: 0.6362 - val_loss: 2.7434 - val_acc: 0.3735\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 2.69156\n",
      "Epoch 233/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5539 - acc: 0.6387 - val_loss: 2.7068 - val_acc: 0.3859\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 2.69156\n",
      "Epoch 234/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5717 - acc: 0.6413 - val_loss: 2.6973 - val_acc: 0.3765\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 2.69156\n",
      "Epoch 235/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.5496 - acc: 0.6423 - val_loss: 2.7244 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 2.69156\n",
      "Epoch 236/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5504 - acc: 0.6429 - val_loss: 2.7121 - val_acc: 0.3782\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 2.69156\n",
      "Epoch 237/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5435 - acc: 0.6482 - val_loss: 2.7570 - val_acc: 0.3799\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 2.69156\n",
      "Epoch 238/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5385 - acc: 0.6501 - val_loss: 2.7040 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 2.69156\n",
      "Epoch 239/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5438 - acc: 0.6482 - val_loss: 2.6865 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00239: val_loss improved from 2.69156 to 2.68654, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 240/1000\n",
      "182/182 [==============================] - 134s 735ms/step - loss: 1.5352 - acc: 0.6444 - val_loss: 2.7088 - val_acc: 0.3782\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 2.68654\n",
      "Epoch 241/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.5552 - acc: 0.6437 - val_loss: 2.7043 - val_acc: 0.3761\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 2.68654\n",
      "Epoch 242/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.5375 - acc: 0.6552 - val_loss: 2.7122 - val_acc: 0.3846\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 2.68654\n",
      "Epoch 243/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5281 - acc: 0.6489 - val_loss: 2.7114 - val_acc: 0.3803\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 2.68654\n",
      "Epoch 244/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.5380 - acc: 0.6423 - val_loss: 2.6783 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00244: val_loss improved from 2.68654 to 2.67827, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 245/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5434 - acc: 0.6435 - val_loss: 2.7332 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 2.67827\n",
      "Epoch 246/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5134 - acc: 0.6520 - val_loss: 2.6792 - val_acc: 0.3816\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 2.67827\n",
      "Epoch 247/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.5166 - acc: 0.6554 - val_loss: 2.6415 - val_acc: 0.3871\n",
      "\n",
      "Epoch 00247: val_loss improved from 2.67827 to 2.64152, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 248/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5169 - acc: 0.6564 - val_loss: 2.6952 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 2.64152\n",
      "Epoch 249/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5235 - acc: 0.6446 - val_loss: 2.7205 - val_acc: 0.3863\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 2.64152\n",
      "Epoch 250/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5085 - acc: 0.6499 - val_loss: 2.7148 - val_acc: 0.3837\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 2.64152\n",
      "Epoch 251/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.5042 - acc: 0.6492 - val_loss: 2.6710 - val_acc: 0.3931\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 2.64152\n",
      "Epoch 252/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.5190 - acc: 0.6499 - val_loss: 2.7119 - val_acc: 0.3765\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 2.64152\n",
      "Epoch 253/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.5056 - acc: 0.6573 - val_loss: 2.6844 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 2.64152\n",
      "Epoch 254/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.5247 - acc: 0.6475 - val_loss: 2.6984 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 2.64152\n",
      "Epoch 255/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4832 - acc: 0.6506 - val_loss: 2.7135 - val_acc: 0.3876\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 2.64152\n",
      "Epoch 256/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.4887 - acc: 0.6552 - val_loss: 2.7145 - val_acc: 0.3961\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 2.64152\n",
      "Epoch 257/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4841 - acc: 0.6604 - val_loss: 2.7042 - val_acc: 0.3812\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 2.64152\n",
      "Epoch 258/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4952 - acc: 0.6576 - val_loss: 2.6726 - val_acc: 0.3876\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 2.64152\n",
      "Epoch 259/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4844 - acc: 0.6532 - val_loss: 2.7105 - val_acc: 0.3795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00259: val_loss did not improve from 2.64152\n",
      "Epoch 260/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4701 - acc: 0.6549 - val_loss: 2.6767 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 2.64152\n",
      "Epoch 261/1000\n",
      "182/182 [==============================] - 133s 729ms/step - loss: 1.4731 - acc: 0.6638 - val_loss: 2.6594 - val_acc: 0.3871\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 2.64152\n",
      "Epoch 262/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4602 - acc: 0.6600 - val_loss: 2.6533 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 2.64152\n",
      "Epoch 263/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.4563 - acc: 0.6654 - val_loss: 2.6824 - val_acc: 0.3829\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 2.64152\n",
      "Epoch 264/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4696 - acc: 0.6611 - val_loss: 2.6931 - val_acc: 0.3859\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 2.64152\n",
      "Epoch 265/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4458 - acc: 0.6652 - val_loss: 2.6805 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 2.64152\n",
      "Epoch 266/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4504 - acc: 0.6635 - val_loss: 2.6715 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 2.64152\n",
      "Epoch 267/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.4679 - acc: 0.6576 - val_loss: 2.6943 - val_acc: 0.3871\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 2.64152\n",
      "Epoch 268/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4371 - acc: 0.6714 - val_loss: 2.6798 - val_acc: 0.3944\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 2.64152\n",
      "Epoch 269/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4607 - acc: 0.6583 - val_loss: 2.6241 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00269: val_loss improved from 2.64152 to 2.62408, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 270/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4516 - acc: 0.6597 - val_loss: 2.6529 - val_acc: 0.3940\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 2.62408\n",
      "Epoch 271/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4263 - acc: 0.6665 - val_loss: 2.6527 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 2.62408\n",
      "Epoch 272/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4321 - acc: 0.6653 - val_loss: 2.6920 - val_acc: 0.3739\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 2.62408\n",
      "Epoch 273/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4453 - acc: 0.6657 - val_loss: 2.7232 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 2.62408\n",
      "Epoch 274/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.4415 - acc: 0.6679 - val_loss: 2.7102 - val_acc: 0.3922\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 2.62408\n",
      "Epoch 275/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4348 - acc: 0.6636 - val_loss: 2.6621 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 2.62408\n",
      "Epoch 276/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.4222 - acc: 0.6616 - val_loss: 2.6540 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 2.62408\n",
      "Epoch 277/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4436 - acc: 0.6686 - val_loss: 2.7013 - val_acc: 0.3795\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 2.62408\n",
      "Epoch 278/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4337 - acc: 0.6537 - val_loss: 2.6865 - val_acc: 0.3935\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 2.62408\n",
      "Epoch 279/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4218 - acc: 0.6746 - val_loss: 2.6972 - val_acc: 0.3961\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 2.62408\n",
      "Epoch 280/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.4246 - acc: 0.6679 - val_loss: 2.6765 - val_acc: 0.3935\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 2.62408\n",
      "Epoch 281/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4475 - acc: 0.6597 - val_loss: 2.6511 - val_acc: 0.3914\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 2.62408\n",
      "Epoch 282/1000\n",
      "182/182 [==============================] - 134s 734ms/step - loss: 1.4337 - acc: 0.6645 - val_loss: 2.6670 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 2.62408\n",
      "Epoch 283/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.3971 - acc: 0.6710 - val_loss: 2.7130 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 2.62408\n",
      "Epoch 284/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4153 - acc: 0.6655 - val_loss: 2.6763 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 2.62408\n",
      "Epoch 285/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4320 - acc: 0.6653 - val_loss: 2.6634 - val_acc: 0.3905\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 2.62408\n",
      "Epoch 286/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 1.4292 - acc: 0.6594 - val_loss: 2.6530 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 2.62408\n",
      "Epoch 287/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4097 - acc: 0.6657 - val_loss: 2.7173 - val_acc: 0.3863\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 2.62408\n",
      "Epoch 288/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.4178 - acc: 0.6678 - val_loss: 2.6653 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 2.62408\n",
      "Epoch 289/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.4087 - acc: 0.6693 - val_loss: 2.6527 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.62408\n",
      "Epoch 290/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.4026 - acc: 0.6791 - val_loss: 2.6760 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 2.62408\n",
      "Epoch 291/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.4110 - acc: 0.6685 - val_loss: 2.6821 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.62408\n",
      "Epoch 292/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.4005 - acc: 0.6705 - val_loss: 2.6824 - val_acc: 0.3825\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 2.62408\n",
      "Epoch 293/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.4085 - acc: 0.6727 - val_loss: 2.6891 - val_acc: 0.3905\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.62408\n",
      "Epoch 294/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.3835 - acc: 0.6741 - val_loss: 2.6270 - val_acc: 0.3910\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.62408\n",
      "Epoch 295/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3887 - acc: 0.6681 - val_loss: 2.6418 - val_acc: 0.3965\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 2.62408\n",
      "Epoch 296/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.4003 - acc: 0.6708 - val_loss: 2.6577 - val_acc: 0.4008\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.62408\n",
      "Epoch 297/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3711 - acc: 0.6837 - val_loss: 2.6387 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 2.62408\n",
      "Epoch 298/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3709 - acc: 0.6781 - val_loss: 2.6773 - val_acc: 0.3922\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.62408\n",
      "Epoch 299/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3886 - acc: 0.6724 - val_loss: 2.6941 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 2.62408\n",
      "Epoch 300/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.4032 - acc: 0.6732 - val_loss: 2.6706 - val_acc: 0.3778\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.62408\n",
      "Epoch 301/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.4016 - acc: 0.6662 - val_loss: 2.6569 - val_acc: 0.3910\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 2.62408\n",
      "Epoch 302/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3791 - acc: 0.6739 - val_loss: 2.6867 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 2.62408\n",
      "Epoch 303/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3698 - acc: 0.6724 - val_loss: 2.6702 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 2.62408\n",
      "Epoch 304/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3744 - acc: 0.6654 - val_loss: 2.6545 - val_acc: 0.3991\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.62408\n",
      "Epoch 305/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3624 - acc: 0.6722 - val_loss: 2.6915 - val_acc: 0.3829\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.62408\n",
      "Epoch 306/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3861 - acc: 0.6679 - val_loss: 2.6350 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.62408\n",
      "Epoch 307/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3660 - acc: 0.6757 - val_loss: 2.6215 - val_acc: 0.3948\n",
      "\n",
      "Epoch 00307: val_loss improved from 2.62408 to 2.62155, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 308/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3510 - acc: 0.6865 - val_loss: 2.6383 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.62155\n",
      "Epoch 309/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3932 - acc: 0.6724 - val_loss: 2.6776 - val_acc: 0.4025\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.62155\n",
      "Epoch 310/1000\n",
      "182/182 [==============================] - 131s 723ms/step - loss: 1.3547 - acc: 0.6763 - val_loss: 2.6563 - val_acc: 0.3999\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.62155\n",
      "Epoch 311/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3608 - acc: 0.6721 - val_loss: 2.6499 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.62155\n",
      "Epoch 312/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3632 - acc: 0.6796 - val_loss: 2.6656 - val_acc: 0.4012\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 2.62155\n",
      "Epoch 313/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3525 - acc: 0.6782 - val_loss: 2.6491 - val_acc: 0.4025\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.62155\n",
      "Epoch 314/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3607 - acc: 0.6760 - val_loss: 2.6646 - val_acc: 0.4008\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 2.62155\n",
      "Epoch 315/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3709 - acc: 0.6793 - val_loss: 2.6514 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 2.62155\n",
      "Epoch 316/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3309 - acc: 0.6829 - val_loss: 2.6482 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 2.62155\n",
      "Epoch 317/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3465 - acc: 0.6774 - val_loss: 2.6498 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 2.62155\n",
      "Epoch 318/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3607 - acc: 0.6824 - val_loss: 2.6584 - val_acc: 0.3969\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 2.62155\n",
      "Epoch 319/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3589 - acc: 0.6822 - val_loss: 2.6684 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 2.62155\n",
      "Epoch 320/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3423 - acc: 0.6822 - val_loss: 2.6461 - val_acc: 0.3999\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 2.62155\n",
      "Epoch 321/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3496 - acc: 0.6757 - val_loss: 2.6310 - val_acc: 0.3991\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 2.62155\n",
      "Epoch 322/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3444 - acc: 0.6794 - val_loss: 2.6058 - val_acc: 0.4076\n",
      "\n",
      "Epoch 00322: val_loss improved from 2.62155 to 2.60578, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 323/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3362 - acc: 0.6817 - val_loss: 2.6455 - val_acc: 0.3944\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 2.60578\n",
      "Epoch 324/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3351 - acc: 0.6764 - val_loss: 2.6261 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 2.60578\n",
      "Epoch 325/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3244 - acc: 0.6842 - val_loss: 2.5879 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00325: val_loss improved from 2.60578 to 2.58790, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 326/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3443 - acc: 0.6808 - val_loss: 2.6763 - val_acc: 0.3888\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 2.58790\n",
      "Epoch 327/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3234 - acc: 0.6930 - val_loss: 2.6651 - val_acc: 0.3884\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 2.58790\n",
      "Epoch 328/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3120 - acc: 0.6880 - val_loss: 2.5907 - val_acc: 0.4055\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 2.58790\n",
      "Epoch 329/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3207 - acc: 0.6866 - val_loss: 2.6541 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 2.58790\n",
      "Epoch 330/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3190 - acc: 0.6892 - val_loss: 2.6539 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 2.58790\n",
      "Epoch 331/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3072 - acc: 0.6868 - val_loss: 2.6324 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 2.58790\n",
      "Epoch 332/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3049 - acc: 0.6805 - val_loss: 2.6347 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 2.58790\n",
      "Epoch 333/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.3363 - acc: 0.6813 - val_loss: 2.6158 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 2.58790\n",
      "Epoch 334/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.2860 - acc: 0.6942 - val_loss: 2.6356 - val_acc: 0.4029\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 2.58790\n",
      "Epoch 335/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3359 - acc: 0.6796 - val_loss: 2.6150 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 2.58790\n",
      "Epoch 336/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3119 - acc: 0.6889 - val_loss: 2.6006 - val_acc: 0.4097\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 2.58790\n",
      "Epoch 337/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2930 - acc: 0.6952 - val_loss: 2.6406 - val_acc: 0.3905\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 2.58790\n",
      "Epoch 338/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.3349 - acc: 0.6787 - val_loss: 2.6438 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 2.58790\n",
      "Epoch 339/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3043 - acc: 0.6902 - val_loss: 2.6767 - val_acc: 0.3880\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 2.58790\n",
      "Epoch 340/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2945 - acc: 0.6897 - val_loss: 2.6841 - val_acc: 0.3952\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 2.58790\n",
      "Epoch 341/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.3060 - acc: 0.6904 - val_loss: 2.6872 - val_acc: 0.3982\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 2.58790\n",
      "Epoch 342/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2931 - acc: 0.6945 - val_loss: 2.5921 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 2.58790\n",
      "Epoch 343/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2793 - acc: 0.6964 - val_loss: 2.6110 - val_acc: 0.3995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00343: val_loss did not improve from 2.58790\n",
      "Epoch 344/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2832 - acc: 0.6961 - val_loss: 2.6317 - val_acc: 0.4016\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 2.58790\n",
      "Epoch 345/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.3106 - acc: 0.6813 - val_loss: 2.6436 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 2.58790\n",
      "Epoch 346/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2863 - acc: 0.6887 - val_loss: 2.6274 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 2.58790\n",
      "Epoch 347/1000\n",
      "182/182 [==============================] - 133s 731ms/step - loss: 1.2841 - acc: 0.6944 - val_loss: 2.6087 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 2.58790\n",
      "Epoch 348/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2865 - acc: 0.6926 - val_loss: 2.6417 - val_acc: 0.3948\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 2.58790\n",
      "Epoch 349/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2822 - acc: 0.6872 - val_loss: 2.6354 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 2.58790\n",
      "Epoch 350/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2724 - acc: 0.6916 - val_loss: 2.6575 - val_acc: 0.3978\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 2.58790\n",
      "Epoch 351/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2686 - acc: 0.6944 - val_loss: 2.6170 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 2.58790\n",
      "Epoch 352/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2439 - acc: 0.7115 - val_loss: 2.5865 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00352: val_loss improved from 2.58790 to 2.58653, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 353/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2601 - acc: 0.6925 - val_loss: 2.6126 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 2.58653\n",
      "Epoch 354/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2752 - acc: 0.6968 - val_loss: 2.6290 - val_acc: 0.4050\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 2.58653\n",
      "Epoch 355/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2765 - acc: 0.6887 - val_loss: 2.6130 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 2.58653\n",
      "Epoch 356/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2455 - acc: 0.7031 - val_loss: 2.6101 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 2.58653\n",
      "Epoch 357/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2691 - acc: 0.6947 - val_loss: 2.6379 - val_acc: 0.3837\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 2.58653\n",
      "Epoch 358/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2608 - acc: 0.6915 - val_loss: 2.6281 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 2.58653\n",
      "Epoch 359/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2681 - acc: 0.6933 - val_loss: 2.6161 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 2.58653\n",
      "Epoch 360/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2830 - acc: 0.6878 - val_loss: 2.6171 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 2.58653\n",
      "Epoch 361/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2647 - acc: 0.6933 - val_loss: 2.6025 - val_acc: 0.4055\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 2.58653\n",
      "Epoch 362/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2547 - acc: 0.6981 - val_loss: 2.6002 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 2.58653\n",
      "Epoch 363/1000\n",
      "182/182 [==============================] - 131s 719ms/step - loss: 1.2730 - acc: 0.6959 - val_loss: 2.6320 - val_acc: 0.4029\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 2.58653\n",
      "Epoch 364/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2608 - acc: 0.6987 - val_loss: 2.5926 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 2.58653\n",
      "Epoch 365/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2644 - acc: 0.6951 - val_loss: 2.6355 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 2.58653\n",
      "Epoch 366/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2784 - acc: 0.6887 - val_loss: 2.6216 - val_acc: 0.3974\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 2.58653\n",
      "Epoch 367/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2444 - acc: 0.6968 - val_loss: 2.6016 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 2.58653\n",
      "Epoch 368/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2290 - acc: 0.7014 - val_loss: 2.6036 - val_acc: 0.4050\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 2.58653\n",
      "Epoch 369/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2483 - acc: 0.6973 - val_loss: 2.6272 - val_acc: 0.4080\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 2.58653\n",
      "Epoch 370/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2657 - acc: 0.6882 - val_loss: 2.6738 - val_acc: 0.3905\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 2.58653\n",
      "Epoch 371/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.2408 - acc: 0.7023 - val_loss: 2.5919 - val_acc: 0.4097\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 2.58653\n",
      "Epoch 372/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2448 - acc: 0.6988 - val_loss: 2.6305 - val_acc: 0.4076\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 2.58653\n",
      "Epoch 373/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2239 - acc: 0.7009 - val_loss: 2.6393 - val_acc: 0.3991\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 2.58653\n",
      "Epoch 374/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2397 - acc: 0.7045 - val_loss: 2.6087 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 2.58653\n",
      "Epoch 375/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2521 - acc: 0.6980 - val_loss: 2.6080 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 2.58653\n",
      "Epoch 376/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.2594 - acc: 0.6947 - val_loss: 2.6176 - val_acc: 0.4089\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 2.58653\n",
      "Epoch 377/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2334 - acc: 0.6997 - val_loss: 2.6229 - val_acc: 0.4033\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 2.58653\n",
      "Epoch 378/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2265 - acc: 0.7021 - val_loss: 2.6445 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 2.58653\n",
      "Epoch 379/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2277 - acc: 0.7043 - val_loss: 2.6377 - val_acc: 0.4016\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 2.58653\n",
      "Epoch 380/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2196 - acc: 0.7064 - val_loss: 2.6044 - val_acc: 0.4020\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 2.58653\n",
      "Epoch 381/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2247 - acc: 0.7033 - val_loss: 2.6037 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 2.58653\n",
      "Epoch 382/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2138 - acc: 0.7090 - val_loss: 2.6200 - val_acc: 0.3986\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 2.58653\n",
      "Epoch 383/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.2098 - acc: 0.7069 - val_loss: 2.6186 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 2.58653\n",
      "Epoch 384/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2200 - acc: 0.7064 - val_loss: 2.5899 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 2.58653\n",
      "Epoch 385/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2315 - acc: 0.7007 - val_loss: 2.6424 - val_acc: 0.3918\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 2.58653\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 723ms/step - loss: 1.2109 - acc: 0.7047 - val_loss: 2.6263 - val_acc: 0.4029\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 2.58653\n",
      "Epoch 387/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2130 - acc: 0.7059 - val_loss: 2.6556 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 2.58653\n",
      "Epoch 388/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2088 - acc: 0.7043 - val_loss: 2.6100 - val_acc: 0.4008\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 2.58653\n",
      "Epoch 389/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2283 - acc: 0.6957 - val_loss: 2.6170 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 2.58653\n",
      "Epoch 390/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.2322 - acc: 0.7040 - val_loss: 2.6260 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 2.58653\n",
      "Epoch 391/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2087 - acc: 0.7035 - val_loss: 2.5842 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00391: val_loss improved from 2.58653 to 2.58420, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 392/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2183 - acc: 0.7066 - val_loss: 2.6016 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 2.58420\n",
      "Epoch 393/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.1931 - acc: 0.7114 - val_loss: 2.6131 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 2.58420\n",
      "Epoch 394/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2097 - acc: 0.7038 - val_loss: 2.6477 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 2.58420\n",
      "Epoch 395/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2049 - acc: 0.7062 - val_loss: 2.5750 - val_acc: 0.4123\n",
      "\n",
      "Epoch 00395: val_loss improved from 2.58420 to 2.57497, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 396/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1944 - acc: 0.7117 - val_loss: 2.5989 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 2.57497\n",
      "Epoch 397/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2071 - acc: 0.7002 - val_loss: 2.6054 - val_acc: 0.4076\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 2.57497\n",
      "Epoch 398/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2117 - acc: 0.7038 - val_loss: 2.6219 - val_acc: 0.4012\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 2.57497\n",
      "Epoch 399/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.1802 - acc: 0.7121 - val_loss: 2.6184 - val_acc: 0.4055\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 2.57497\n",
      "Epoch 400/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1916 - acc: 0.7098 - val_loss: 2.5729 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00400: val_loss improved from 2.57497 to 2.57285, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 401/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1901 - acc: 0.7040 - val_loss: 2.6622 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 2.57285\n",
      "Epoch 402/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.2047 - acc: 0.7119 - val_loss: 2.6638 - val_acc: 0.4050\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 2.57285\n",
      "Epoch 403/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1960 - acc: 0.7115 - val_loss: 2.6653 - val_acc: 0.3867\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 2.57285\n",
      "Epoch 404/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.2071 - acc: 0.7053 - val_loss: 2.5976 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 2.57285\n",
      "Epoch 405/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.1924 - acc: 0.7052 - val_loss: 2.5912 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 2.57285\n",
      "Epoch 406/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1950 - acc: 0.7028 - val_loss: 2.5908 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 2.57285\n",
      "Epoch 407/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1881 - acc: 0.7035 - val_loss: 2.5609 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00407: val_loss improved from 2.57285 to 2.56093, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 408/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.1788 - acc: 0.7124 - val_loss: 2.5888 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 2.56093\n",
      "Epoch 409/1000\n",
      "182/182 [==============================] - 131s 718ms/step - loss: 1.1981 - acc: 0.7048 - val_loss: 2.6041 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 2.56093\n",
      "Epoch 410/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1751 - acc: 0.7131 - val_loss: 2.6122 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 2.56093\n",
      "Epoch 411/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1934 - acc: 0.7102 - val_loss: 2.6170 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 2.56093\n",
      "Epoch 412/1000\n",
      "182/182 [==============================] - 131s 719ms/step - loss: 1.1834 - acc: 0.7103 - val_loss: 2.6313 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 2.56093\n",
      "Epoch 413/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1649 - acc: 0.7211 - val_loss: 2.6126 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 2.56093\n",
      "Epoch 414/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1697 - acc: 0.7124 - val_loss: 2.6017 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 2.56093\n",
      "Epoch 415/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1689 - acc: 0.7181 - val_loss: 2.6003 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 2.56093\n",
      "Epoch 416/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1829 - acc: 0.7148 - val_loss: 2.5375 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00416: val_loss improved from 2.56093 to 2.53751, saving model to Saved_Models/weights.best.from_scratch42.hdf5\n",
      "Epoch 417/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1587 - acc: 0.7170 - val_loss: 2.6378 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 2.53751\n",
      "Epoch 418/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1745 - acc: 0.7136 - val_loss: 2.5714 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 2.53751\n",
      "Epoch 419/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1711 - acc: 0.7170 - val_loss: 2.6529 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 2.53751\n",
      "Epoch 420/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1761 - acc: 0.7079 - val_loss: 2.6086 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 2.53751\n",
      "Epoch 421/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.1953 - acc: 0.7047 - val_loss: 2.6368 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 2.53751\n",
      "Epoch 422/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.1595 - acc: 0.7090 - val_loss: 2.5906 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 2.53751\n",
      "Epoch 423/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1842 - acc: 0.7052 - val_loss: 2.5942 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 2.53751\n",
      "Epoch 424/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.1664 - acc: 0.7100 - val_loss: 2.6143 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 2.53751\n",
      "Epoch 425/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.1670 - acc: 0.7172 - val_loss: 2.6286 - val_acc: 0.3995\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 2.53751\n",
      "Epoch 426/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1501 - acc: 0.7186 - val_loss: 2.6156 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 2.53751\n",
      "Epoch 427/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1492 - acc: 0.7218 - val_loss: 2.6082 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 2.53751\n",
      "Epoch 428/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1901 - acc: 0.7112 - val_loss: 2.6242 - val_acc: 0.4029\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 2.53751\n",
      "Epoch 429/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1568 - acc: 0.7129 - val_loss: 2.6205 - val_acc: 0.4106\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 2.53751\n",
      "Epoch 430/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1566 - acc: 0.7227 - val_loss: 2.6609 - val_acc: 0.4016\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 2.53751\n",
      "Epoch 431/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1388 - acc: 0.7227 - val_loss: 2.5948 - val_acc: 0.3965\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 2.53751\n",
      "Epoch 432/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1707 - acc: 0.7129 - val_loss: 2.5535 - val_acc: 0.4225\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 2.53751\n",
      "Epoch 433/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1592 - acc: 0.7148 - val_loss: 2.5720 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 2.53751\n",
      "Epoch 434/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1618 - acc: 0.7186 - val_loss: 2.6271 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 2.53751\n",
      "Epoch 435/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1777 - acc: 0.7071 - val_loss: 2.5839 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 2.53751\n",
      "Epoch 436/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1545 - acc: 0.7074 - val_loss: 2.5887 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 2.53751\n",
      "Epoch 437/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1346 - acc: 0.7200 - val_loss: 2.6212 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 2.53751\n",
      "Epoch 438/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.1712 - acc: 0.7115 - val_loss: 2.6389 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 2.53751\n",
      "Epoch 439/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1563 - acc: 0.7169 - val_loss: 2.6087 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 2.53751\n",
      "Epoch 440/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1641 - acc: 0.7182 - val_loss: 2.6157 - val_acc: 0.4097\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 2.53751\n",
      "Epoch 441/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1339 - acc: 0.7194 - val_loss: 2.5607 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 2.53751\n",
      "Epoch 442/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1469 - acc: 0.7145 - val_loss: 2.6189 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 2.53751\n",
      "Epoch 443/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1425 - acc: 0.7169 - val_loss: 2.6671 - val_acc: 0.4055\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 2.53751\n",
      "Epoch 444/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1327 - acc: 0.7177 - val_loss: 2.5999 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 2.53751\n",
      "Epoch 445/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1496 - acc: 0.7224 - val_loss: 2.6224 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 2.53751\n",
      "Epoch 446/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1421 - acc: 0.7181 - val_loss: 2.6386 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 2.53751\n",
      "Epoch 447/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1761 - acc: 0.7060 - val_loss: 2.6393 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 2.53751\n",
      "Epoch 448/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1712 - acc: 0.7074 - val_loss: 2.6210 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 2.53751\n",
      "Epoch 449/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1307 - acc: 0.7175 - val_loss: 2.6430 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 2.53751\n",
      "Epoch 450/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1365 - acc: 0.7194 - val_loss: 2.5870 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 2.53751\n",
      "Epoch 451/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1251 - acc: 0.7222 - val_loss: 2.6042 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 2.53751\n",
      "Epoch 452/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1192 - acc: 0.7258 - val_loss: 2.6219 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 2.53751\n",
      "Epoch 453/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1072 - acc: 0.7313 - val_loss: 2.6065 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 2.53751\n",
      "Epoch 454/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1241 - acc: 0.7232 - val_loss: 2.5996 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 2.53751\n",
      "Epoch 455/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1236 - acc: 0.7182 - val_loss: 2.5791 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 2.53751\n",
      "Epoch 456/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1178 - acc: 0.7218 - val_loss: 2.5979 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 2.53751\n",
      "Epoch 457/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1397 - acc: 0.7213 - val_loss: 2.6134 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 2.53751\n",
      "Epoch 458/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 1.1331 - acc: 0.7205 - val_loss: 2.6308 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 2.53751\n",
      "Epoch 459/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1101 - acc: 0.7220 - val_loss: 2.5858 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 2.53751\n",
      "Epoch 460/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1263 - acc: 0.7237 - val_loss: 2.5812 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 2.53751\n",
      "Epoch 461/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1131 - acc: 0.7299 - val_loss: 2.5896 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 2.53751\n",
      "Epoch 462/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0916 - acc: 0.7327 - val_loss: 2.6370 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 2.53751\n",
      "Epoch 463/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.1227 - acc: 0.7222 - val_loss: 2.5931 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 2.53751\n",
      "Epoch 464/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1339 - acc: 0.7172 - val_loss: 2.6024 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 2.53751\n",
      "Epoch 465/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 1.0991 - acc: 0.7227 - val_loss: 2.6064 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 2.53751\n",
      "Epoch 466/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.1070 - acc: 0.7282 - val_loss: 2.6044 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 2.53751\n",
      "Epoch 467/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1075 - acc: 0.7253 - val_loss: 2.6669 - val_acc: 0.4046\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 2.53751\n",
      "Epoch 468/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1276 - acc: 0.7129 - val_loss: 2.6619 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 2.53751\n",
      "Epoch 469/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.1104 - acc: 0.7215 - val_loss: 2.5873 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 2.53751\n",
      "Epoch 470/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1309 - acc: 0.7164 - val_loss: 2.6101 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 2.53751\n",
      "Epoch 471/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1188 - acc: 0.7200 - val_loss: 2.6099 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 2.53751\n",
      "Epoch 472/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1039 - acc: 0.7273 - val_loss: 2.6405 - val_acc: 0.4089\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 2.53751\n",
      "Epoch 473/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1203 - acc: 0.7217 - val_loss: 2.5880 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 2.53751\n",
      "Epoch 474/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0968 - acc: 0.7272 - val_loss: 2.5913 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 2.53751\n",
      "Epoch 475/1000\n",
      "182/182 [==============================] - 134s 737ms/step - loss: 1.1035 - acc: 0.7177 - val_loss: 2.6206 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 2.53751\n",
      "Epoch 476/1000\n",
      "182/182 [==============================] - 138s 756ms/step - loss: 1.1044 - acc: 0.7217 - val_loss: 2.5791 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 2.53751\n",
      "Epoch 477/1000\n",
      "182/182 [==============================] - 136s 746ms/step - loss: 1.1095 - acc: 0.7290 - val_loss: 2.6035 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 2.53751\n",
      "Epoch 478/1000\n",
      "182/182 [==============================] - 136s 745ms/step - loss: 1.0864 - acc: 0.7284 - val_loss: 2.6354 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 2.53751\n",
      "Epoch 479/1000\n",
      "182/182 [==============================] - 133s 732ms/step - loss: 1.0855 - acc: 0.7246 - val_loss: 2.6074 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 2.53751\n",
      "Epoch 480/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0936 - acc: 0.7313 - val_loss: 2.5708 - val_acc: 0.4042\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 2.53751\n",
      "Epoch 481/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0992 - acc: 0.7260 - val_loss: 2.6044 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 2.53751\n",
      "Epoch 482/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1243 - acc: 0.7215 - val_loss: 2.5826 - val_acc: 0.4208\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 2.53751\n",
      "Epoch 483/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1069 - acc: 0.7174 - val_loss: 2.6191 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 2.53751\n",
      "Epoch 484/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0984 - acc: 0.7234 - val_loss: 2.6549 - val_acc: 0.4076\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 2.53751\n",
      "Epoch 485/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1235 - acc: 0.7174 - val_loss: 2.6102 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 2.53751\n",
      "Epoch 486/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.1289 - acc: 0.7210 - val_loss: 2.5612 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 2.53751\n",
      "Epoch 487/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.1272 - acc: 0.7220 - val_loss: 2.5789 - val_acc: 0.4123\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 2.53751\n",
      "Epoch 488/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0886 - acc: 0.7244 - val_loss: 2.6059 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 2.53751\n",
      "Epoch 489/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0886 - acc: 0.7217 - val_loss: 2.5860 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 2.53751\n",
      "Epoch 490/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0974 - acc: 0.7242 - val_loss: 2.6159 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 2.53751\n",
      "Epoch 491/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0972 - acc: 0.7291 - val_loss: 2.6013 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 2.53751\n",
      "Epoch 492/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0881 - acc: 0.7268 - val_loss: 2.5993 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 2.53751\n",
      "Epoch 493/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0978 - acc: 0.7303 - val_loss: 2.5829 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 2.53751\n",
      "Epoch 494/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0842 - acc: 0.7254 - val_loss: 2.6097 - val_acc: 0.4110\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 2.53751\n",
      "Epoch 495/1000\n",
      "182/182 [==============================] - 139s 762ms/step - loss: 1.0931 - acc: 0.7227 - val_loss: 2.6069 - val_acc: 0.4037\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 2.53751\n",
      "Epoch 496/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0732 - acc: 0.7291 - val_loss: 2.5971 - val_acc: 0.4216\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 2.53751\n",
      "Epoch 497/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 1.0932 - acc: 0.7225 - val_loss: 2.6117 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 2.53751\n",
      "Epoch 498/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0812 - acc: 0.7290 - val_loss: 2.5754 - val_acc: 0.4106\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 2.53751\n",
      "Epoch 499/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0685 - acc: 0.7294 - val_loss: 2.5968 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 2.53751\n",
      "Epoch 500/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0736 - acc: 0.7306 - val_loss: 2.5721 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 2.53751\n",
      "Epoch 501/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0838 - acc: 0.7224 - val_loss: 2.5809 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 2.53751\n",
      "Epoch 502/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0970 - acc: 0.7285 - val_loss: 2.5703 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 2.53751\n",
      "Epoch 503/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0650 - acc: 0.7335 - val_loss: 2.5640 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 2.53751\n",
      "Epoch 504/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0791 - acc: 0.7347 - val_loss: 2.6371 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 2.53751\n",
      "Epoch 505/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0826 - acc: 0.7254 - val_loss: 2.6224 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 2.53751\n",
      "Epoch 506/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0752 - acc: 0.7321 - val_loss: 2.5865 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 2.53751\n",
      "Epoch 507/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0577 - acc: 0.7344 - val_loss: 2.6234 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 2.53751\n",
      "Epoch 508/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0794 - acc: 0.7273 - val_loss: 2.5965 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 2.53751\n",
      "Epoch 509/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0892 - acc: 0.7277 - val_loss: 2.5740 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 2.53751\n",
      "Epoch 510/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0640 - acc: 0.7330 - val_loss: 2.6224 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 2.53751\n",
      "Epoch 511/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0890 - acc: 0.7277 - val_loss: 2.6380 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 2.53751\n",
      "Epoch 512/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 1.0777 - acc: 0.7277 - val_loss: 2.6559 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 2.53751\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0750 - acc: 0.7323 - val_loss: 2.6247 - val_acc: 0.4072\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 2.53751\n",
      "Epoch 514/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0671 - acc: 0.7337 - val_loss: 2.5919 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 2.53751\n",
      "Epoch 515/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0849 - acc: 0.7356 - val_loss: 2.6443 - val_acc: 0.4025\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 2.53751\n",
      "Epoch 516/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0680 - acc: 0.7318 - val_loss: 2.6187 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 2.53751\n",
      "Epoch 517/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0456 - acc: 0.7342 - val_loss: 2.5621 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 2.53751\n",
      "Epoch 518/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.1009 - acc: 0.7191 - val_loss: 2.6179 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 2.53751\n",
      "Epoch 519/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0559 - acc: 0.7333 - val_loss: 2.5505 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 2.53751\n",
      "Epoch 520/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0611 - acc: 0.7399 - val_loss: 2.5980 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 2.53751\n",
      "Epoch 521/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0666 - acc: 0.7328 - val_loss: 2.6125 - val_acc: 0.4246\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 2.53751\n",
      "Epoch 522/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0721 - acc: 0.7249 - val_loss: 2.5916 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 2.53751\n",
      "Epoch 523/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0682 - acc: 0.7347 - val_loss: 2.5848 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 2.53751\n",
      "Epoch 524/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0574 - acc: 0.7327 - val_loss: 2.5954 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 2.53751\n",
      "Epoch 525/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0741 - acc: 0.7309 - val_loss: 2.5918 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 2.53751\n",
      "Epoch 526/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0542 - acc: 0.7347 - val_loss: 2.6083 - val_acc: 0.4246\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 2.53751\n",
      "Epoch 527/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0606 - acc: 0.7315 - val_loss: 2.6110 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 2.53751\n",
      "Epoch 528/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0764 - acc: 0.7277 - val_loss: 2.6046 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 2.53751\n",
      "Epoch 529/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0705 - acc: 0.7304 - val_loss: 2.6246 - val_acc: 0.4135\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 2.53751\n",
      "Epoch 530/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0466 - acc: 0.7311 - val_loss: 2.6190 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 2.53751\n",
      "Epoch 531/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0665 - acc: 0.7302 - val_loss: 2.5501 - val_acc: 0.4365\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 2.53751\n",
      "Epoch 532/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0337 - acc: 0.7363 - val_loss: 2.5997 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 2.53751\n",
      "Epoch 533/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0323 - acc: 0.7370 - val_loss: 2.5726 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 2.53751\n",
      "Epoch 534/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0526 - acc: 0.7354 - val_loss: 2.6099 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 2.53751\n",
      "Epoch 535/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0355 - acc: 0.7335 - val_loss: 2.6121 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 2.53751\n",
      "Epoch 536/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0607 - acc: 0.7309 - val_loss: 2.6528 - val_acc: 0.4216\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 2.53751\n",
      "Epoch 537/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0258 - acc: 0.7407 - val_loss: 2.6089 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 2.53751\n",
      "Epoch 538/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0423 - acc: 0.7369 - val_loss: 2.5796 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 2.53751\n",
      "Epoch 539/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0701 - acc: 0.7282 - val_loss: 2.5485 - val_acc: 0.4263\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 2.53751\n",
      "Epoch 540/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 1.0378 - acc: 0.7404 - val_loss: 2.5524 - val_acc: 0.4361\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 2.53751\n",
      "Epoch 541/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0547 - acc: 0.7253 - val_loss: 2.6064 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 2.53751\n",
      "Epoch 542/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0409 - acc: 0.7375 - val_loss: 2.6068 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 2.53751\n",
      "Epoch 543/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0320 - acc: 0.7390 - val_loss: 2.5870 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 2.53751\n",
      "Epoch 544/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0194 - acc: 0.7485 - val_loss: 2.6019 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 2.53751\n",
      "Epoch 545/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0477 - acc: 0.7392 - val_loss: 2.6183 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 2.53751\n",
      "Epoch 546/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0522 - acc: 0.7323 - val_loss: 2.6230 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 2.53751\n",
      "Epoch 547/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0511 - acc: 0.7327 - val_loss: 2.6467 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 2.53751\n",
      "Epoch 548/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0352 - acc: 0.7394 - val_loss: 2.5959 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 2.53751\n",
      "Epoch 549/1000\n",
      "182/182 [==============================] - 133s 733ms/step - loss: 1.0544 - acc: 0.7321 - val_loss: 2.5713 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 2.53751\n",
      "Epoch 550/1000\n",
      "182/182 [==============================] - 133s 729ms/step - loss: 1.0297 - acc: 0.7460 - val_loss: 2.6034 - val_acc: 0.4263\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 2.53751\n",
      "Epoch 551/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0291 - acc: 0.7431 - val_loss: 2.5808 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 2.53751\n",
      "Epoch 552/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0489 - acc: 0.7340 - val_loss: 2.6608 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 2.53751\n",
      "Epoch 553/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0244 - acc: 0.7378 - val_loss: 2.6518 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 2.53751\n",
      "Epoch 554/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0031 - acc: 0.7491 - val_loss: 2.5831 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 2.53751\n",
      "Epoch 555/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0390 - acc: 0.7400 - val_loss: 2.5828 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 2.53751\n",
      "Epoch 556/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0167 - acc: 0.7486 - val_loss: 2.6310 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 2.53751\n",
      "Epoch 557/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0465 - acc: 0.7344 - val_loss: 2.6302 - val_acc: 0.4148\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 2.53751\n",
      "Epoch 558/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0208 - acc: 0.7390 - val_loss: 2.6351 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 2.53751\n",
      "Epoch 559/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0382 - acc: 0.7323 - val_loss: 2.6480 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 2.53751\n",
      "Epoch 560/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0139 - acc: 0.7464 - val_loss: 2.5897 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 2.53751\n",
      "Epoch 561/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0512 - acc: 0.7344 - val_loss: 2.6119 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 2.53751\n",
      "Epoch 562/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0172 - acc: 0.7443 - val_loss: 2.5930 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 2.53751\n",
      "Epoch 563/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0179 - acc: 0.7366 - val_loss: 2.6424 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 2.53751\n",
      "Epoch 564/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0426 - acc: 0.7304 - val_loss: 2.5771 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 2.53751\n",
      "Epoch 565/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0232 - acc: 0.7457 - val_loss: 2.6160 - val_acc: 0.4106\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 2.53751\n",
      "Epoch 566/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0249 - acc: 0.7412 - val_loss: 2.6089 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 2.53751\n",
      "Epoch 567/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0044 - acc: 0.7454 - val_loss: 2.5849 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 2.53751\n",
      "Epoch 568/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0145 - acc: 0.7421 - val_loss: 2.6164 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 2.53751\n",
      "Epoch 569/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0230 - acc: 0.7349 - val_loss: 2.6050 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 2.53751\n",
      "Epoch 570/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.0080 - acc: 0.7428 - val_loss: 2.6044 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 2.53751\n",
      "Epoch 571/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0237 - acc: 0.7457 - val_loss: 2.6055 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 2.53751\n",
      "Epoch 572/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0095 - acc: 0.7466 - val_loss: 2.6318 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 2.53751\n",
      "Epoch 573/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0040 - acc: 0.7406 - val_loss: 2.6037 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 2.53751\n",
      "Epoch 574/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0043 - acc: 0.7442 - val_loss: 2.5882 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 2.53751\n",
      "Epoch 575/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.0269 - acc: 0.7388 - val_loss: 2.5774 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 2.53751\n",
      "Epoch 576/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0311 - acc: 0.7395 - val_loss: 2.5782 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 2.53751\n",
      "Epoch 577/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0051 - acc: 0.7435 - val_loss: 2.6002 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 2.53751\n",
      "Epoch 578/1000\n",
      "182/182 [==============================] - 131s 723ms/step - loss: 1.0014 - acc: 0.7442 - val_loss: 2.6395 - val_acc: 0.4059\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 2.53751\n",
      "Epoch 579/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0158 - acc: 0.7416 - val_loss: 2.6566 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 2.53751\n",
      "Epoch 580/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0064 - acc: 0.7461 - val_loss: 2.6448 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 2.53751\n",
      "Epoch 581/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0006 - acc: 0.7481 - val_loss: 2.6382 - val_acc: 0.4063\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 2.53751\n",
      "Epoch 582/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0227 - acc: 0.7369 - val_loss: 2.5848 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 2.53751\n",
      "Epoch 583/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0129 - acc: 0.7430 - val_loss: 2.6258 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 2.53751\n",
      "Epoch 584/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0078 - acc: 0.7411 - val_loss: 2.5752 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 2.53751\n",
      "Epoch 585/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0044 - acc: 0.7433 - val_loss: 2.5887 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 2.53751\n",
      "Epoch 586/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9947 - acc: 0.7490 - val_loss: 2.5871 - val_acc: 0.4225\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 2.53751\n",
      "Epoch 587/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0217 - acc: 0.7430 - val_loss: 2.5853 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 2.53751\n",
      "Epoch 588/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0185 - acc: 0.7318 - val_loss: 2.6120 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 2.53751\n",
      "Epoch 589/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0007 - acc: 0.7448 - val_loss: 2.6293 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 2.53751\n",
      "Epoch 590/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0168 - acc: 0.7418 - val_loss: 2.6121 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 2.53751\n",
      "Epoch 591/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0064 - acc: 0.7466 - val_loss: 2.6117 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 2.53751\n",
      "Epoch 592/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9937 - acc: 0.7469 - val_loss: 2.5820 - val_acc: 0.4391\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 2.53751\n",
      "Epoch 593/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 1.0045 - acc: 0.7467 - val_loss: 2.6567 - val_acc: 0.4080\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 2.53751\n",
      "Epoch 594/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0093 - acc: 0.7436 - val_loss: 2.5509 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 2.53751\n",
      "Epoch 595/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 1.0148 - acc: 0.7375 - val_loss: 2.6086 - val_acc: 0.4263\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 2.53751\n",
      "Epoch 596/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0024 - acc: 0.7435 - val_loss: 2.5978 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 2.53751\n",
      "Epoch 597/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9958 - acc: 0.7472 - val_loss: 2.6108 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 2.53751\n",
      "Epoch 598/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 1.0167 - acc: 0.7407 - val_loss: 2.6384 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 2.53751\n",
      "Epoch 599/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0034 - acc: 0.7416 - val_loss: 2.5931 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 2.53751\n",
      "Epoch 600/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 0.9972 - acc: 0.7514 - val_loss: 2.5872 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 2.53751\n",
      "Epoch 601/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0120 - acc: 0.7411 - val_loss: 2.5977 - val_acc: 0.4357\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 2.53751\n",
      "Epoch 602/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 0.9905 - acc: 0.7423 - val_loss: 2.6573 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 2.53751\n",
      "Epoch 603/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 1.0051 - acc: 0.7389 - val_loss: 2.6235 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 2.53751\n",
      "Epoch 604/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 1.0018 - acc: 0.7443 - val_loss: 2.5746 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 2.53751\n",
      "Epoch 605/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 1.0184 - acc: 0.7349 - val_loss: 2.6052 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 2.53751\n",
      "Epoch 606/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9933 - acc: 0.7440 - val_loss: 2.6218 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 2.53751\n",
      "Epoch 607/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9891 - acc: 0.7462 - val_loss: 2.6294 - val_acc: 0.4101\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 2.53751\n",
      "Epoch 608/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9868 - acc: 0.7448 - val_loss: 2.6294 - val_acc: 0.4093\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 2.53751\n",
      "Epoch 609/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9998 - acc: 0.7402 - val_loss: 2.5625 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 2.53751\n",
      "Epoch 610/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9921 - acc: 0.7402 - val_loss: 2.5779 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 2.53751\n",
      "Epoch 611/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9862 - acc: 0.7514 - val_loss: 2.6378 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 2.53751\n",
      "Epoch 612/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9965 - acc: 0.7471 - val_loss: 2.6062 - val_acc: 0.4336\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 2.53751\n",
      "Epoch 613/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0004 - acc: 0.7369 - val_loss: 2.5839 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 2.53751\n",
      "Epoch 614/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9927 - acc: 0.7533 - val_loss: 2.5862 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 2.53751\n",
      "Epoch 615/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9923 - acc: 0.7481 - val_loss: 2.6127 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 2.53751\n",
      "Epoch 616/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9705 - acc: 0.7539 - val_loss: 2.6360 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 2.53751\n",
      "Epoch 617/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9846 - acc: 0.7491 - val_loss: 2.5749 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 2.53751\n",
      "Epoch 618/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 1.0012 - acc: 0.7474 - val_loss: 2.5656 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 2.53751\n",
      "Epoch 619/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9899 - acc: 0.7495 - val_loss: 2.6507 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 2.53751\n",
      "Epoch 620/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9721 - acc: 0.7569 - val_loss: 2.6245 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 2.53751\n",
      "Epoch 621/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9662 - acc: 0.7519 - val_loss: 2.6141 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 2.53751\n",
      "Epoch 622/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9900 - acc: 0.7507 - val_loss: 2.6611 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 2.53751\n",
      "Epoch 623/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9965 - acc: 0.7529 - val_loss: 2.6156 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 2.53751\n",
      "Epoch 624/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9922 - acc: 0.7457 - val_loss: 2.6818 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 2.53751\n",
      "Epoch 625/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9923 - acc: 0.7426 - val_loss: 2.5606 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 2.53751\n",
      "Epoch 626/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9897 - acc: 0.7452 - val_loss: 2.5964 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 2.53751\n",
      "Epoch 627/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9971 - acc: 0.7433 - val_loss: 2.6707 - val_acc: 0.4131\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 2.53751\n",
      "Epoch 628/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9770 - acc: 0.7558 - val_loss: 2.6348 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 2.53751\n",
      "Epoch 629/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9747 - acc: 0.7512 - val_loss: 2.6533 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 2.53751\n",
      "Epoch 630/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9648 - acc: 0.7550 - val_loss: 2.5912 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 2.53751\n",
      "Epoch 631/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9626 - acc: 0.7503 - val_loss: 2.6096 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 2.53751\n",
      "Epoch 632/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9829 - acc: 0.7467 - val_loss: 2.5671 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 2.53751\n",
      "Epoch 633/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9897 - acc: 0.7411 - val_loss: 2.6049 - val_acc: 0.4208\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 2.53751\n",
      "Epoch 634/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9798 - acc: 0.7528 - val_loss: 2.6630 - val_acc: 0.4067\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 2.53751\n",
      "Epoch 635/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9830 - acc: 0.7493 - val_loss: 2.6151 - val_acc: 0.4127\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 2.53751\n",
      "Epoch 636/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9822 - acc: 0.7461 - val_loss: 2.6476 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 2.53751\n",
      "Epoch 637/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9682 - acc: 0.7510 - val_loss: 2.6165 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 2.53751\n",
      "Epoch 638/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9591 - acc: 0.7524 - val_loss: 2.6367 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 2.53751\n",
      "Epoch 639/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9756 - acc: 0.7440 - val_loss: 2.5611 - val_acc: 0.4225\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 2.53751\n",
      "Epoch 640/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9712 - acc: 0.7459 - val_loss: 2.6373 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 2.53751\n",
      "Epoch 641/1000\n",
      "182/182 [==============================] - 131s 723ms/step - loss: 0.9607 - acc: 0.7546 - val_loss: 2.6420 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 2.53751\n",
      "Epoch 642/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9685 - acc: 0.7496 - val_loss: 2.6489 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 2.53751\n",
      "Epoch 643/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9842 - acc: 0.7464 - val_loss: 2.6066 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 2.53751\n",
      "Epoch 644/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9702 - acc: 0.7505 - val_loss: 2.6285 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 2.53751\n",
      "Epoch 645/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9622 - acc: 0.7543 - val_loss: 2.5699 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 2.53751\n",
      "Epoch 646/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9550 - acc: 0.7555 - val_loss: 2.6187 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 2.53751\n",
      "Epoch 647/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 0.9626 - acc: 0.7445 - val_loss: 2.6093 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 2.53751\n",
      "Epoch 648/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9514 - acc: 0.7577 - val_loss: 2.6207 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 2.53751\n",
      "Epoch 649/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9890 - acc: 0.7488 - val_loss: 2.6098 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 2.53751\n",
      "Epoch 650/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9351 - acc: 0.7586 - val_loss: 2.6291 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 2.53751\n",
      "Epoch 651/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9396 - acc: 0.7552 - val_loss: 2.6067 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 2.53751\n",
      "Epoch 652/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9603 - acc: 0.7553 - val_loss: 2.5770 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 2.53751\n",
      "Epoch 653/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9687 - acc: 0.7541 - val_loss: 2.6035 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 2.53751\n",
      "Epoch 654/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9568 - acc: 0.7574 - val_loss: 2.5635 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 2.53751\n",
      "Epoch 655/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9510 - acc: 0.7570 - val_loss: 2.6448 - val_acc: 0.4199\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 2.53751\n",
      "Epoch 656/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9441 - acc: 0.7579 - val_loss: 2.5926 - val_acc: 0.4391\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 2.53751\n",
      "Epoch 657/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9696 - acc: 0.7495 - val_loss: 2.6091 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 2.53751\n",
      "Epoch 658/1000\n",
      "182/182 [==============================] - 131s 723ms/step - loss: 0.9523 - acc: 0.7500 - val_loss: 2.6162 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 2.53751\n",
      "Epoch 659/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9803 - acc: 0.7466 - val_loss: 2.5807 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 2.53751\n",
      "Epoch 660/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9475 - acc: 0.7522 - val_loss: 2.6124 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 2.53751\n",
      "Epoch 661/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 0.9491 - acc: 0.7510 - val_loss: 2.5873 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 2.53751\n",
      "Epoch 662/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9517 - acc: 0.7579 - val_loss: 2.6365 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 2.53751\n",
      "Epoch 663/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9364 - acc: 0.7531 - val_loss: 2.5952 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 2.53751\n",
      "Epoch 664/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9284 - acc: 0.7624 - val_loss: 2.5828 - val_acc: 0.4404\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 2.53751\n",
      "Epoch 665/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9433 - acc: 0.7533 - val_loss: 2.6471 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 2.53751\n",
      "Epoch 666/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9466 - acc: 0.7603 - val_loss: 2.6173 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 2.53751\n",
      "Epoch 667/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9308 - acc: 0.7539 - val_loss: 2.6327 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 2.53751\n",
      "Epoch 668/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9317 - acc: 0.7582 - val_loss: 2.6051 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 2.53751\n",
      "Epoch 669/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 0.9578 - acc: 0.7531 - val_loss: 2.6752 - val_acc: 0.4012\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 2.53751\n",
      "Epoch 670/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9430 - acc: 0.7536 - val_loss: 2.5756 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 2.53751\n",
      "Epoch 671/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9314 - acc: 0.7586 - val_loss: 2.6778 - val_acc: 0.4097\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 2.53751\n",
      "Epoch 672/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9571 - acc: 0.7582 - val_loss: 2.6004 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 2.53751\n",
      "Epoch 673/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9494 - acc: 0.7541 - val_loss: 2.6085 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 2.53751\n",
      "Epoch 674/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9685 - acc: 0.7474 - val_loss: 2.5437 - val_acc: 0.4446\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 2.53751\n",
      "Epoch 675/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9512 - acc: 0.7517 - val_loss: 2.6058 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 2.53751\n",
      "Epoch 676/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9525 - acc: 0.7493 - val_loss: 2.6436 - val_acc: 0.4191\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 2.53751\n",
      "Epoch 677/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9416 - acc: 0.7519 - val_loss: 2.6178 - val_acc: 0.4272\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 2.53751\n",
      "Epoch 678/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9367 - acc: 0.7572 - val_loss: 2.6009 - val_acc: 0.4357\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 2.53751\n",
      "Epoch 679/1000\n",
      "182/182 [==============================] - 132s 726ms/step - loss: 0.9468 - acc: 0.7486 - val_loss: 2.6250 - val_acc: 0.4118\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 2.53751\n",
      "Epoch 680/1000\n",
      "182/182 [==============================] - 131s 723ms/step - loss: 0.9319 - acc: 0.7540 - val_loss: 2.6525 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 2.53751\n",
      "Epoch 681/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9526 - acc: 0.7524 - val_loss: 2.6373 - val_acc: 0.4331\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 2.53751\n",
      "Epoch 682/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9450 - acc: 0.7497 - val_loss: 2.6101 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 2.53751\n",
      "Epoch 683/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9429 - acc: 0.7502 - val_loss: 2.5736 - val_acc: 0.4302\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 2.53751\n",
      "Epoch 684/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9432 - acc: 0.7534 - val_loss: 2.5883 - val_acc: 0.4250\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 2.53751\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9232 - acc: 0.7608 - val_loss: 2.6084 - val_acc: 0.4182\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 2.53751\n",
      "Epoch 686/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9443 - acc: 0.7522 - val_loss: 2.5995 - val_acc: 0.4178\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 2.53751\n",
      "Epoch 687/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9109 - acc: 0.7598 - val_loss: 2.6488 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 2.53751\n",
      "Epoch 688/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9246 - acc: 0.7552 - val_loss: 2.6004 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 2.53751\n",
      "Epoch 689/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9376 - acc: 0.7527 - val_loss: 2.6526 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 2.53751\n",
      "Epoch 690/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9373 - acc: 0.7529 - val_loss: 2.6797 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 2.53751\n",
      "Epoch 691/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9668 - acc: 0.7478 - val_loss: 2.6133 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 2.53751\n",
      "Epoch 692/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9434 - acc: 0.7570 - val_loss: 2.6440 - val_acc: 0.4276\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 2.53751\n",
      "Epoch 693/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9451 - acc: 0.7527 - val_loss: 2.5834 - val_acc: 0.4246\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 2.53751\n",
      "Epoch 694/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9632 - acc: 0.7522 - val_loss: 2.6408 - val_acc: 0.4344\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 2.53751\n",
      "Epoch 695/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9179 - acc: 0.7563 - val_loss: 2.5981 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 2.53751\n",
      "Epoch 696/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9436 - acc: 0.7507 - val_loss: 2.6451 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 2.53751\n",
      "Epoch 697/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9563 - acc: 0.7464 - val_loss: 2.6407 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 2.53751\n",
      "Epoch 698/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9028 - acc: 0.7643 - val_loss: 2.5857 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 2.53751\n",
      "Epoch 699/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9328 - acc: 0.7581 - val_loss: 2.5797 - val_acc: 0.4221\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 2.53751\n",
      "Epoch 700/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9488 - acc: 0.7471 - val_loss: 2.5975 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 2.53751\n",
      "Epoch 701/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9104 - acc: 0.7600 - val_loss: 2.6703 - val_acc: 0.4229\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 2.53751\n",
      "Epoch 702/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9347 - acc: 0.7553 - val_loss: 2.6461 - val_acc: 0.4123\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 2.53751\n",
      "Epoch 703/1000\n",
      "182/182 [==============================] - 133s 729ms/step - loss: 0.9214 - acc: 0.7606 - val_loss: 2.6546 - val_acc: 0.4314\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 2.53751\n",
      "Epoch 704/1000\n",
      "182/182 [==============================] - 133s 730ms/step - loss: 0.9465 - acc: 0.7531 - val_loss: 2.6137 - val_acc: 0.4233\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 2.53751\n",
      "Epoch 705/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9439 - acc: 0.7543 - val_loss: 2.6832 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 2.53751\n",
      "Epoch 706/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9274 - acc: 0.7545 - val_loss: 2.6078 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 2.53751\n",
      "Epoch 707/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9266 - acc: 0.7594 - val_loss: 2.5994 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 2.53751\n",
      "Epoch 708/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9359 - acc: 0.7510 - val_loss: 2.5689 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 2.53751\n",
      "Epoch 709/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9056 - acc: 0.7612 - val_loss: 2.6401 - val_acc: 0.4140\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 2.53751\n",
      "Epoch 710/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9190 - acc: 0.7632 - val_loss: 2.6867 - val_acc: 0.4084\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 2.53751\n",
      "Epoch 711/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9392 - acc: 0.7557 - val_loss: 2.6405 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 2.53751\n",
      "Epoch 712/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9443 - acc: 0.7536 - val_loss: 2.6062 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 2.53751\n",
      "Epoch 713/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9115 - acc: 0.7655 - val_loss: 2.6475 - val_acc: 0.4174\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 2.53751\n",
      "Epoch 714/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.8888 - acc: 0.7675 - val_loss: 2.5922 - val_acc: 0.4246\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 2.53751\n",
      "Epoch 715/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9339 - acc: 0.7584 - val_loss: 2.6185 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 2.53751\n",
      "Epoch 716/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9193 - acc: 0.7582 - val_loss: 2.5869 - val_acc: 0.4408\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 2.53751\n",
      "Epoch 717/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9200 - acc: 0.7595 - val_loss: 2.6352 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 2.53751\n",
      "Epoch 718/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9243 - acc: 0.7586 - val_loss: 2.6264 - val_acc: 0.4187\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 2.53751\n",
      "Epoch 719/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9138 - acc: 0.7588 - val_loss: 2.6460 - val_acc: 0.4165\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 2.53751\n",
      "Epoch 720/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9276 - acc: 0.7570 - val_loss: 2.6368 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 2.53751\n",
      "Epoch 721/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9240 - acc: 0.7594 - val_loss: 2.6292 - val_acc: 0.4319\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 2.53751\n",
      "Epoch 722/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9313 - acc: 0.7615 - val_loss: 2.6110 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 2.53751\n",
      "Epoch 723/1000\n",
      "182/182 [==============================] - 131s 720ms/step - loss: 0.9138 - acc: 0.7591 - val_loss: 2.7063 - val_acc: 0.4144\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 2.53751\n",
      "Epoch 724/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9274 - acc: 0.7531 - val_loss: 2.6024 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 2.53751\n",
      "Epoch 725/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9255 - acc: 0.7519 - val_loss: 2.6045 - val_acc: 0.4293\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 2.53751\n",
      "Epoch 726/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9154 - acc: 0.7665 - val_loss: 2.6237 - val_acc: 0.4297\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 2.53751\n",
      "Epoch 727/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9160 - acc: 0.7581 - val_loss: 2.6765 - val_acc: 0.4306\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 2.53751\n",
      "Epoch 728/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9311 - acc: 0.7593 - val_loss: 2.6406 - val_acc: 0.4114\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 2.53751\n",
      "Epoch 729/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9303 - acc: 0.7613 - val_loss: 2.6060 - val_acc: 0.4391\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 2.53751\n",
      "Epoch 730/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9381 - acc: 0.7541 - val_loss: 2.6612 - val_acc: 0.4161\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 2.53751\n",
      "Epoch 731/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9252 - acc: 0.7575 - val_loss: 2.5470 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 2.53751\n",
      "Epoch 732/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9043 - acc: 0.7634 - val_loss: 2.6431 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 2.53751\n",
      "Epoch 733/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9186 - acc: 0.7593 - val_loss: 2.6581 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 2.53751\n",
      "Epoch 734/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9259 - acc: 0.7605 - val_loss: 2.5892 - val_acc: 0.4323\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 2.53751\n",
      "Epoch 735/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9136 - acc: 0.7656 - val_loss: 2.6194 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 2.53751\n",
      "Epoch 736/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9033 - acc: 0.7656 - val_loss: 2.6339 - val_acc: 0.4255\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 2.53751\n",
      "Epoch 737/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.8980 - acc: 0.7653 - val_loss: 2.6256 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 2.53751\n",
      "Epoch 738/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.8969 - acc: 0.7582 - val_loss: 2.7055 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 2.53751\n",
      "Epoch 739/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9092 - acc: 0.7630 - val_loss: 2.6159 - val_acc: 0.4319\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 2.53751\n",
      "Epoch 740/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9166 - acc: 0.7684 - val_loss: 2.6173 - val_acc: 0.4353\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 2.53751\n",
      "Epoch 741/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9120 - acc: 0.7591 - val_loss: 2.5842 - val_acc: 0.4357\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 2.53751\n",
      "Epoch 742/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9090 - acc: 0.7651 - val_loss: 2.6790 - val_acc: 0.4246\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 2.53751\n",
      "Epoch 743/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9242 - acc: 0.7560 - val_loss: 2.6275 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 2.53751\n",
      "Epoch 744/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9060 - acc: 0.7560 - val_loss: 2.6863 - val_acc: 0.4170\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 2.53751\n",
      "Epoch 745/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9117 - acc: 0.7620 - val_loss: 2.6310 - val_acc: 0.4374\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 2.53751\n",
      "Epoch 746/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.9080 - acc: 0.7588 - val_loss: 2.6425 - val_acc: 0.4242\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 2.53751\n",
      "Epoch 747/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9308 - acc: 0.7517 - val_loss: 2.6328 - val_acc: 0.4152\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 2.53751\n",
      "Epoch 748/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.9112 - acc: 0.7660 - val_loss: 2.6093 - val_acc: 0.4280\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 2.53751\n",
      "Epoch 749/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9276 - acc: 0.7564 - val_loss: 2.6583 - val_acc: 0.4212\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 2.53751\n",
      "Epoch 750/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.8953 - acc: 0.7706 - val_loss: 2.6540 - val_acc: 0.4195\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 2.53751\n",
      "Epoch 751/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9005 - acc: 0.7646 - val_loss: 2.6164 - val_acc: 0.4310\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 2.53751\n",
      "Epoch 752/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.8846 - acc: 0.7696 - val_loss: 2.6721 - val_acc: 0.4267\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 2.53751\n",
      "Epoch 753/1000\n",
      "182/182 [==============================] - 131s 721ms/step - loss: 0.8836 - acc: 0.7708 - val_loss: 2.6470 - val_acc: 0.4259\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 2.53751\n",
      "Epoch 754/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9089 - acc: 0.7636 - val_loss: 2.5973 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 2.53751\n",
      "Epoch 755/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.9175 - acc: 0.7576 - val_loss: 2.6144 - val_acc: 0.4238\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 2.53751\n",
      "Epoch 756/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9132 - acc: 0.7582 - val_loss: 2.5851 - val_acc: 0.4289\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 2.53751\n",
      "Epoch 757/1000\n",
      "182/182 [==============================] - 132s 723ms/step - loss: 0.8856 - acc: 0.7634 - val_loss: 2.6791 - val_acc: 0.4412\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 2.53751\n",
      "Epoch 758/1000\n",
      "182/182 [==============================] - 132s 724ms/step - loss: 0.8914 - acc: 0.7656 - val_loss: 2.6624 - val_acc: 0.4225\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 2.53751\n",
      "Epoch 759/1000\n",
      "182/182 [==============================] - 132s 727ms/step - loss: 0.9104 - acc: 0.7577 - val_loss: 2.6551 - val_acc: 0.4370\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 2.53751\n",
      "Epoch 760/1000\n",
      "182/182 [==============================] - 132s 725ms/step - loss: 0.9032 - acc: 0.7603 - val_loss: 2.6662 - val_acc: 0.4204\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 2.53751\n",
      "Epoch 761/1000\n",
      "182/182 [==============================] - 131s 722ms/step - loss: 0.9158 - acc: 0.7560 - val_loss: 2.6517 - val_acc: 0.4340\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 2.53751\n",
      "Epoch 762/1000\n",
      "181/182 [============================>.] - ETA: 0s - loss: 0.8911 - acc: 0.7605"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-0b5f725637be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m           callbacks=[checkpointer])\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;31m# model.fit(train_data, test_data,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m#                   callbacks = [checkpointer],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    232\u001b[0m                             \u001b[0mval_enqueuer_gen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                             workers=0)\n\u001b[0m\u001b[0;32m    235\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m                         \u001b[1;31m# No need for try/except because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1470\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1472\u001b[1;33m             verbose=verbose)\n\u001b[0m\u001b[0;32m   1473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1474\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m             \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                 raise ValueError('Output of generator should be a tuple '\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='Saved_Models/weights.best.from_scratch42.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Saving = model.fit_generator(train_data,\n",
    "          steps_per_epoch=182,  \n",
    "          epochs=epochs,\n",
    "          verbose=1, \n",
    "          validation_data=test_data,\n",
    "          validation_steps=74,\n",
    "          callbacks=[checkpointer])\n",
    "# model.fit(train_data, test_data,\n",
    "#                   callbacks = [checkpointer],\n",
    "#                   validation_split = 0.33,\n",
    "#                   epochs=epochs,\n",
    "#           batch_size = 20,\n",
    "#           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vals = pd.DataFrame.from_dict(Saving.history)\n",
    "vals = pd.concat([pd.Series(range(0,100),name='epochs'),vals],axis=1)\n",
    "vals.head(n=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style({'xtick.bottom':False,\n",
    "               'ytick.left':False,\n",
    "               'axes.spines.bottom': False,\n",
    "               'axes.spines.left': False,\n",
    "               'axes.spines.right': False,\n",
    "               'axes.spines.top': False})\n",
    "\n",
    "ig,(ax,ax1) = plt.subplots(nrows=2,ncols=1,figsize=(20,20))\n",
    "sns.scatterplot(x='epochs',y='acc',data=vals,ax=ax,color='r')\n",
    "sns.lineplot(x='epochs',y='val_acc',data=vals,ax=ax,color='g')\n",
    "sns.scatterplot(x='epochs',y='loss',data=vals,ax=ax1,color='r')\n",
    "sns.lineplot(x='epochs',y='val_loss',data=vals,ax=ax1,color='g')\n",
    "ax.legend(labels=['Test Accuracy','Training Accuracy'])\n",
    "ax1.legend(labels=['Test Loss','Training Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(n_iterations):\n",
    "#         print('\\r{}/{}'. format(i, n_iterations))\n",
    "#         #initilaize random hyperparameters\n",
    "#         random_parameters = {K: random.sample(V, 1)[0] for K, V in parameters_grid.items()}\n",
    "#         #create model with random hyperparameters\n",
    "#         model = create_model(random_parameters)\n",
    "#         opt = create_RMSprop_optimizer(random_parameters)\n",
    "#         #compile model\n",
    "#         model.compile(optimizer = opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#         #train model\n",
    "#         epochs = 40\n",
    "#         checkpointer = ModelCheckpoint(filepath='saved_models/model_weights.hdf5', verbose=1, save_best_only=True)\n",
    "#         early_stopping = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 8)\n",
    "#         history = model.fit(X_train, Y_train,\n",
    "#                   callbacks = [checkpointer, early_stopping],\n",
    "#                   validation_split = 0.33,\n",
    "#                   epochs=epochs, batch_size = 20, verbose=1)\n",
    "#         #compare current min validation loss with global min validation loss\n",
    "#         current_min_val_loss = np.min(history.history['val_loss'])\n",
    "#         if(current_min_val_loss < global_min_val_loss):\n",
    "#             global_min_val_loss = current_min_val_loss\n",
    "#             #save the best model so far\n",
    "#             model.load_weights('saved_models/model_weights.hdf5')\n",
    "#             model.save('saved_models/best_model.h5')\n",
    "#             print('saving new best model, val_loss = {}'.format(current_min_val_loss))\n",
    "#             #save best hyperparameters\n",
    "#             best_hyperparameters = random_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
